{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1ef9fea7-4567-4318-9e5e-941a3148b622",
   "metadata": {},
   "source": [
    "# EMBED Data Engineering\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6e454b9-07ad-4151-a2dd-757ba69ab014",
   "metadata": {},
   "source": [
    "![embed_logical_steps](images/embed_logical_steps.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ec55952-d541-43cc-97ff-84c242fba62b",
   "metadata": {},
   "source": [
    "## Defining our clinical sample"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40f10e85-b781-4252-90f5-7b18dbcee596",
   "metadata": {},
   "source": [
    "An understanding of the basic diagnostic pathway for breast cancer is important to working with EMBED. The graphic below shows a basic summary of the standard pathway for most patients.\n",
    "\n",
    "![0_full_pathway](images/0_full_pathway.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3b1845a-f181-4691-bdb6-ced3f07ad440",
   "metadata": {},
   "source": [
    "---\n",
    "# 1. Clinical Sample Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec6419e2-7c2a-422b-9906-8c060ad7f3f6",
   "metadata": {},
   "source": [
    "---\n",
    "# 1a. Screening Abnormal vs Normal\n",
    "\n",
    "\n",
    "### Objectives: \n",
    "\n",
    "1. **Positive group**:\n",
    "    - Screening BIRADS 0\n",
    "2. **Negative group**:\n",
    "    - Screening BIRADS 1/2\n",
    "\n",
    "\n",
    "![1a](images/1a.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7e3535e-38f3-4f4d-b925-7aba817514df",
   "metadata": {},
   "source": [
    "## 1a.1. Prep\n",
    "> ## You should be using the `pandas` environment!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "68b46477-9402-4352-a209-7332b9ec9b6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "import pickle\n",
    "from IPython.display import display\n",
    "import pydicom\n",
    "from dataclasses import dataclass, field\n",
    "from tableone import TableOne\n",
    "\n",
    "# these let us set the number of rows/cols of our dataframes we want to see\n",
    "# EMBED has a lot of columns so it's a good idea to increase this from the default\n",
    "pd.set_option('display.max_rows', 50)\n",
    "pd.set_option('display.max_columns', 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "01bbe640-695e-4f37-b4d7-33d2e6bfb717",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataframe_stats(df, title: str or None = None):\n",
    "    \"\"\"\n",
    "    helper function to check the number of patients, exams, and images/findings in a df\n",
    "    \"\"\"\n",
    "    if title is not None:\n",
    "        print(f\"\\n{title}\")\n",
    "        \n",
    "    num_patients = df.empi_anon.nunique()\n",
    "    num_exams = df.acc_anon.nunique()\n",
    "    \n",
    "    print(f\"Patients: {num_patients}\")\n",
    "    print(f\"Exams: {num_exams}\")\n",
    "    \n",
    "    if 'png_path' in df.columns:\n",
    "        print(f\"Images: {df.png_path.nunique()}\\n\")\n",
    "    else:\n",
    "        print(f\"Findings: {len(df)}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d497b4f-ebce-4a59-9a74-5bc4cd622bad",
   "metadata": {},
   "source": [
    "The tables for EMBED can be found in `/fsx/embed/emory-mammo/tables/`. There are two versions of both Magview and metadata, one containing a reduced set of important columns, and one containing all columns. This notebook uses the full datasets and defines a specific subset to keep, but the reduced set should be suitable for most tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "5870e5a9-01bb-42e0-9e47-06cee119d479",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['filtered_magview.csv',\n",
       " 'filtered_magview_reduced.csv',\n",
       " '.aws-datasync',\n",
       " 'filtered_metadata.csv',\n",
       " 'filtered_metadata_MRI_anon.csv',\n",
       " 'filtered_metadata_reduced.csv']"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir('/fsx/embed/emory-mammo/tables')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "41b99fcd-c273-40ca-985b-43e370fd6c0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we're working with 20% of the total data today (and during the datathon)\n",
    "mag_df = pd.read_csv(\"/fsx/embed/emory-mammo/tables/filtered_magview.csv\", dtype=str)\n",
    "meta_df = pd.read_csv(\"/fsx/embed/emory-mammo/tables/filtered_metadata.csv\", dtype=str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "07053467-9111-4d99-bd91-28158a31923f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "magview\n",
      "Patients: 32463\n",
      "Exams: 90497\n",
      "Findings: 105731\n",
      "\n",
      "\n",
      "metadata\n",
      "Patients: 31998\n",
      "Exams: 86221\n",
      "Images: 567152\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dataframe_stats(mag_df, 'magview')\n",
    "dataframe_stats(meta_df, 'metadata')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f516783-80e6-4aaa-9d45-72142e6f19d1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "86f1a15c-046f-4e9b-afda-42259aa8b276",
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_cols = [\n",
    "    \"empi_anon\",\n",
    "    \"acc_anon\",\n",
    "    \"ImageLateralityFinal\",\n",
    "    \"ViewPosition\",\n",
    "    \"study_date_anon\",\n",
    "    \"FinalImageType\",\n",
    "    \"png_path\",\n",
    "    \"anon_dicom_path\",\n",
    "    \"StudyDescription\",\n",
    "    \"ROI_match_level\",\n",
    "    \"num_roi\",\n",
    "    \"PNG_ROI_coords\",\n",
    "    \"DCM_ROI_coords\",\n",
    "    \"spot_mag\"\n",
    "]\n",
    "\n",
    "mag_cols = [\n",
    "    \"empi_anon\",\n",
    "    \"acc_anon\",\n",
    "    \"study_date_anon\",\n",
    "    \"desc\",\n",
    "    \"side\",\n",
    "    \"asses\",\n",
    "    \"path_severity\",\n",
    "    \"bside\",\n",
    "    'procdate_anon',\n",
    "    'pdate_anon',\n",
    "    'massshape', \n",
    "    'massmargin', \n",
    "    'massdens', \n",
    "    'calcdistri', \n",
    "    'calcfind', \n",
    "    'calcnumber',\n",
    "    'tissueden',\n",
    "    \"ETHNICITY_DESC\", \n",
    "    \"ETHNIC_GROUP_DESC\", \n",
    "    \"MARITAL_STATUS_DESC\", \n",
    "    \"age_at_study\",\n",
    "    \"numfind\"\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97ee924d-2516-45d1-8091-c03dbb3e685c",
   "metadata": {},
   "source": [
    "##### Check datatypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "13b407fc-c61f-4658-888f-b27a2b1837c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# only keep the subset of columns we need\n",
    "# we'll need to re-load the magview/metadata CSVs if we want additional columns\n",
    "meta_df = meta_df[meta_cols]\n",
    "mag_df = mag_df[mag_cols]\n",
    "\n",
    "# we need to ensure our date columns are read as dates\n",
    "meta_df.study_date_anon = pd.to_datetime(meta_df.study_date_anon)\n",
    "mag_df.study_date_anon = pd.to_datetime(mag_df.study_date_anon)\n",
    "\n",
    "# and our numeric columns are read as numeric\n",
    "meta_df.num_roi = meta_df.num_roi.astype(int)\n",
    "meta_df.num_roi = pd.to_numeric(meta_df.num_roi)\n",
    "mag_df.path_severity = pd.to_numeric(mag_df.path_severity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88ddcd7e-ee86-402a-8c57-fc97a90407d3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "89b051a7-ede5-4f80-8ce0-a7b71e3e03e9",
   "metadata": {},
   "source": [
    "## 1a.2. Screening\n",
    "\n",
    "Screening and diagnostic exams can be most easily differentiated with the 'desc' column which contains the description of the study\n",
    "![1_screening](images/1_screening.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "ac9c07f8-cfdf-47c5-b8f7-fc6e178c2788",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "desc\n",
       "MG Screen Bilat w/Tomo/CAD Stnd Protocol    48061\n",
       "MG Diagnostic Bilateral w/ CAD              11246\n",
       "MG Screening Bilateral                       9885\n",
       "MG Screening Bilateral w/CAD                 7385\n",
       "MG Diagnostic Left w/CAD                     5502\n",
       "MG Diagnostic Right w/CAD                    5460\n",
       "MG Diagnostic Mammo Bilateral                4680\n",
       "MG Diagnostic Left                           3060\n",
       "MG Diagnostic Right                          2984\n",
       "MG Diagnostic Bilateral w/Tomo/CAD           2344\n",
       "MG Screening Left w/Tomo/CAD                  943\n",
       "MG Diagnostic  Right w/Tomo/CAD               880\n",
       "MG Diagnostic  Left w/Tomo/CAD                870\n",
       "MG Screening Right w/Tomo/CAD                 857\n",
       "MG Diagnostic Bilateral w/Tomosynthesis       404\n",
       "MG Screening Right w/CAD                      360\n",
       "MG Screening Left w/CAD                       297\n",
       "MG Screening Bilat w/Tomosynthesis            132\n",
       "MG Screening Left                             119\n",
       "MG Screening Right                            105\n",
       "MG Diagnostic  Left w/Tomosynthesis            82\n",
       "MG Diagnostic  Right w/Tomosynthesis           61\n",
       "MG Diagnostic Bilateral CESM                   14\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mag_df.desc.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "fd9421e6-94dc-4544-9532-97b097f02ca6",
   "metadata": {},
   "outputs": [],
   "source": [
    "mag_screen = mag_df.loc[mag_df.desc.str.contains(\"scr\", case=False)].copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "78315700-00ca-489b-9b86-112960516055",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "magview screen\n",
      "Patients: 25086\n",
      "Exams: 63399\n",
      "Findings: 68144\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dataframe_stats(mag_screen, 'magview screen')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16d4bc99-6f96-44b3-8964-bb03f21230a5",
   "metadata": {},
   "source": [
    "> ## Question\n",
    ">\n",
    "> **If we wanted to filter for diagnostic exams instead, how do you think we could achieve this?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cec7a7b-13da-4c43-8222-4b376e4a6a78",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6eea1d20-49b8-4647-b9b6-d63d47e0d563",
   "metadata": {},
   "source": [
    "## 1a.3. Correct Contralaterals\n",
    "\n",
    "- MAGVIEW only has entries if a finding exists.\n",
    "- This means that if an exam is a bilateral exam and only one of the breast has a finding, the contralateral breast (negative) won't have an entry.\n",
    "- This would be problematic at the time when we need to merge with METADATA, because the contralateral breast would be excluded.\n",
    "- Therefore, we would need to create rows for the negative contralateral breast.\n",
    "![contralat_correction](images/contralat_correction.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "8695b759-3ed7-4210-b918-65a90eeff884",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_exam_laterality(row):\n",
    "    # extract description and lowercase it\n",
    "    finding_desc = row.desc.lower()\n",
    "    \n",
    "    if (\"bilat\" in finding_desc):\n",
    "        return \"B\"\n",
    "    elif (\"left\" in finding_desc):\n",
    "        return \"L\"\n",
    "    elif (\"right\" in finding_desc):\n",
    "        return \"R\"\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "def apply_contralateral_correction(df):\n",
    "    \"\"\"\n",
    "    function to apply a contralateral finding correction to a dataframe of screening exams\n",
    "    \"\"\"\n",
    "    # apply the get_exam_laterality function to extract laterality from each desc\n",
    "    df[\"exam_laterality\"] = df.apply(get_exam_laterality, axis=1)\n",
    "    \n",
    "    # side == nan --> B\n",
    "    df.side = df.side.fillna(\"B\")\n",
    "    \n",
    "    # create copy for assigning B to R\n",
    "    df_r = df.loc[df.side==\"B\"].copy()\n",
    "    df_r.side = df.side.str.replace(\"B\", \"R\")\n",
    "    \n",
    "    # assigning B to L\n",
    "    df.side = df.side.str.replace(\"B\", \"L\")\n",
    "    \n",
    "    # appending R and L\n",
    "    df = pd.concat([df, df_r])\n",
    "    \n",
    "    df = df.sort_values([\"empi_anon\", \"acc_anon\", \"study_date_anon\"]).drop_duplicates()\n",
    "    \n",
    "    exam_lat_b = df.loc[df.exam_laterality==\"B\"]\n",
    "    \n",
    "    # We want to aggregate all the sides for each bilateral exam so that we can filter those having only a single side.\n",
    "    exam_lat_b_agg = exam_lat_b.groupby('acc_anon')['side'].apply(''.join).reset_index()\n",
    "    \n",
    "    exam_lat_b_side_r = exam_lat_b_agg.loc[~(exam_lat_b_agg.side.str.contains(\"L\"))].copy()\n",
    "    exam_lat_b_side_l = exam_lat_b_agg.loc[~(exam_lat_b_agg.side.str.contains(\"R\"))].copy()\n",
    "    \n",
    "    df_r_to_l = df.loc[df.acc_anon.isin(exam_lat_b_side_r.acc_anon)].copy().drop_duplicates()\n",
    "    df_l_to_r = df.loc[df.acc_anon.isin(exam_lat_b_side_l.acc_anon)].copy().drop_duplicates()\n",
    "    \n",
    "    # Creating the negative Left side\n",
    "    df_r_to_l.loc[df_r_to_l.side==\"R\", \"side\"] = \"L\"\n",
    "    df_r_to_l.loc[df_r_to_l.side==\"L\", \"asses\"] = \"N\"\n",
    "    df_r_to_l.loc[df_r_to_l.side==\"L\", \"path_severity\"] = np.nan\n",
    "    \n",
    "    # Creating the negative Right side\n",
    "    df_l_to_r.loc[df_l_to_r.side==\"L\", \"side\"] = \"R\"\n",
    "    df_l_to_r.loc[df_l_to_r.side==\"R\", \"asses\"] = \"N\"\n",
    "    df_l_to_r.loc[df_l_to_r.side==\"R\", \"path_severity\"] = np.nan\n",
    "    \n",
    "    # Merging the original and the two negative contralaterals\n",
    "    df_contralat = pd.concat([df, df_l_to_r, df_r_to_l]).sort_values([\"empi_anon\", \"acc_anon\", \"study_date_anon\"]).drop_duplicates()\n",
    "    return df_contralat\n",
    "\n",
    "# apply contralateral correction\n",
    "mag_screen_with_contralat = apply_contralateral_correction(mag_screen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "290eb098-2b97-44c8-aeb1-7092152bf8e4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "magview screen with contralat\n",
      "Patients: 25086\n",
      "Exams: 63399\n",
      "Findings: 129439\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dataframe_stats(mag_screen_with_contralat, 'magview screen with contralat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "4a27b10d-e532-4ec3-9766-86fc44a2eff1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "side\n",
       "L    64744\n",
       "R    64695\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# verify finding lateralities\n",
    "mag_screen_with_contralat.side.value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11f17fa9-b79c-4e23-956b-757d83594930",
   "metadata": {},
   "source": [
    "> ## Question:\n",
    ">\n",
    "> **We have:**\n",
    ">\n",
    "> **1. filtered Magview to only contain screening exams and**\n",
    "> \n",
    "> **2. corrected missing contralateral negative findings.**\n",
    "> \n",
    "> **If we want to define a screening normal versus abnormal  sample, what's our next step?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc2f7519-3da8-48e6-9f13-6c4cf196a11b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60707f65-c4fb-4cdf-96c3-c86f55e7576c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ef92b15-d1f9-484f-a84a-b50128c2967c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "384156e3-5261-459f-92bc-44904f0b84e0",
   "metadata": {},
   "source": [
    "| BIRADS | `asses` | Stage | Meaning |\n",
    "| :-: | :-: | :-: | :-- |\n",
    "| 0 | 'A' | Screen | Additional evaluation |\n",
    "| 1 | 'N' | Screen + Diag | Negative |\n",
    "| 2 | 'B' | Screen + Diag | Benign |\n",
    "| 3 | 'P' | Diag | Probably benign |\n",
    "| 4 | 'S' | Diag | Suspicious |\n",
    "| 5 | 'M' | Diag | Highly suggestive of malignacy |\n",
    "| 6 | 'K' | Diag | Known biopsy proven |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0921a2e6-4262-44f7-aaaa-c1798ce45c3c",
   "metadata": {},
   "source": [
    "> Finding BIRADS score can be indexed with the `asses` column\n",
    "> ![1.1_screening](images/1.1_screening.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "e205fb28-d24e-4100-bb52-87c67d809357",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "asses\n",
       "N    102421\n",
       "A     18376\n",
       "B      8540\n",
       "S        78\n",
       "K         9\n",
       "P         8\n",
       "M         5\n",
       "X         2\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mag_screen_with_contralat.asses.value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc55bd32-9634-4ee1-947e-942daab54de6",
   "metadata": {},
   "source": [
    "## 1a.4. Screening BIRADS 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "f1295c2e-ea05-41a4-af1a-1ed7562121dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can select our BIRADS 0 screening exams by selecting screening exams where asses == 'A'\n",
    "scr_br0 = mag_screen_with_contralat.loc[mag_screen_with_contralat.asses.isin([\"A\"])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "6d318c9d-31cc-45b7-9352-e5a4b837a972",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "magview br 0 screen\n",
      "Patients: 12344\n",
      "Exams: 13684\n",
      "Findings: 18376\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dataframe_stats(scr_br0, 'magview br 0 screen')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d354dd55-7d12-46c8-8a0d-a87c55f7f4d1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f1d49404-420e-4bdd-b8b9-90d77512b0f8",
   "metadata": {},
   "source": [
    "## 1a.5. Screening BIRADS 1/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "90b40479-26c1-4dc6-b35c-0f5a1b1aa3df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can select our BIRADS 1/2 screening exams by selecting screening exams where asses == 'N' or 'B'\n",
    "scr_br12 = mag_screen_with_contralat.loc[mag_screen_with_contralat.asses.isin([\"N\", \"B\"])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "a8a0b295-eaaa-4fc7-b52f-c086cd878eaf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "magview br 1/2 screen\n",
      "Patients: 23890\n",
      "Exams: 61005\n",
      "Findings: 110961\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dataframe_stats(scr_br12, 'magview br 1/2 screen')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e43142f7-9ba3-413e-87e9-bf8b650fa7a7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "88a76dca-dc2d-4ee2-936b-e68d0a695b46",
   "metadata": {},
   "source": [
    "## 1a.6. Excluding Positive Patients from the Negative Group\n",
    "To prevent data leakage, we generally ensure there are no patients that overlap between the positive and negative sets\n",
    "\n",
    "> ## Question\n",
    ">\n",
    "> **Is this necessary? What might happen if we don't?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "bcdbe50b-2fda-436c-932d-84a8b14acc40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "filtered negative\n",
      "Patients: 12737\n",
      "Exams: 34240\n",
      "Findings: 67382\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# get a list of empi in the positive set\n",
    "br0_empi_list = list(scr_br0.empi_anon.unique())\n",
    "# exclude all positive empi from the negative set\n",
    "filt_scr_br12 = scr_br12[~scr_br12.empi_anon.isin(br0_empi_list)]\n",
    "\n",
    "dataframe_stats(filt_scr_br12, 'filtered negative')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "d7af06e6-5f59-4706-bde2-7a7593384683",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save our dataframes to new variables so we don't accidentally overwrite them\n",
    "mag_abnorm_df = scr_br0.copy()\n",
    "mag_norm_df = filt_scr_br12.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99b3d8ee-92e5-4ce8-946a-8f3a395037d2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9eb7112-e368-4119-8e13-c21ae3790743",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "af2cbd2f-f6a8-4264-84b9-e660252a4f1d",
   "metadata": {},
   "source": [
    "---\n",
    "# 1b. Cancer vs No Cancer\n",
    "\n",
    "\n",
    "### Objectives: \n",
    "\n",
    "1. **Positive group**:\n",
    "    - Screening BIRADS 0 > Path Severity 0/1\n",
    "    - Any Screening BIRADS > Diagnostic Path Severity 0/1\n",
    "2. **Negative group**:\n",
    "    - Any Screening w/ Path Severity Not 0/1\n",
    "\n",
    "![1b](images/1b.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe6ffab0-2a8f-4ff3-a9ee-881cfb7339bf",
   "metadata": {},
   "source": [
    "> This pipeline will start from the dataframe of contralateral screening findings.\n",
    "## 1b.1. Screening BIRADS 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "5216112d-5648-4cca-a5fc-8d6689c0b6b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can select our BIRADS 0 screening exams by only selecting screening exams where asses == 'A'\n",
    "scr_br0 = mag_screen_with_contralat.loc[mag_screen_with_contralat.asses.isin([\"A\"])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "356884b3-1198-417b-8f76-76bc134580c9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "magview br 0 screen\n",
      "Patients: 12344\n",
      "Exams: 13684\n",
      "Findings: 18376\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dataframe_stats(scr_br0, 'magview br 0 screen')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95d8d36e-1752-45fb-bfa7-6c1e73093e9b",
   "metadata": {},
   "source": [
    "## 1b.2. Screening BIRADS 0 > Path Severity 0/1\n",
    "Pathology findings on subsequent biopsies are SUPPOSED to be updated on the original screening exams, but in practice this is not always the case. To get around this, we'll identify our positive subset in two ways:\n",
    "1. Screening BIRADS 0 Findings with Invasive/Non-Invasive Cancer Pathology\n",
    "   > This is the *intended* behavior, where path findings were reflected to the preceding screening exams\n",
    "2. Screening BIRADS 0 > Diagnostic Invasive/Non-Invasive Cancer Pathology\n",
    "   > This is the *unintended* behavior, where path findings weren't reflected back so we'll have to do it manually! We'll talk more about this in a moment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "b0881cd0-11c2-48db-9892-2d26a5f9a58e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# first, for our easy cases where path findings were correctly reflected back\n",
    "# we can just filter our screening BIRADS 0 findings to exclude any without a\n",
    "# path severity of 0 or 1 (invasive or non-invasive cancer)\n",
    "scr_ps01 = scr_br0.loc[scr_br0.path_severity.isin([0.0, 1.0])]\n",
    "\n",
    "# we also need to make sure to only include findings from the side with the relevant pathology\n",
    "# `side` gives the laterality of the finding and `bside` gives the laterality of the biopsy\n",
    "\n",
    "# why is this necessary? \n",
    "# example scenario: a patient received a bilateral screening BIRADS 0 but their subsequent diagnostic \n",
    "# exam revealed that only the right breast has cancer, we want to only include images from their right breast\n",
    "# in our cancer set\n",
    "scr_ps01 = scr_ps01.loc[(scr_ps01.side == scr_ps01.bside) | (scr_ps01.bside == 'B')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "8eb28b45-33b9-434d-9d49-98a462f1edb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "magview ps 0/1 screen\n",
      "Patients: 1484\n",
      "Exams: 1493\n",
      "Findings: 2255\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dataframe_stats(scr_ps01, 'magview ps 0/1 screen')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1bbcbea-d9e0-4230-b390-ca54666910f1",
   "metadata": {},
   "source": [
    "## 1b.3. Screening Any BIRADS > Not Path Severity 0/1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "a2b85952-4209-4432-98b2-0d37744630a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we'll refine this further, but this is the base of our negative set for this setting\n",
    "# we're selecting all screening exams that *do not* have a path severity of 0 or 1 (invasive or non-invasive cancers)\n",
    "scr_not_ps01 = mag_screen_with_contralat.loc[~mag_screen_with_contralat.path_severity.isin([0.0, 1.0])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "be80095f-811a-4851-a892-1dd2c381a3ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "magview ps not 0/1 screen\n",
      "Patients: 24995\n",
      "Exams: 63288\n",
      "Findings: 127079\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dataframe_stats(scr_not_ps01, 'magview ps not 0/1 screen')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "941fd4e0-13c1-4c41-9835-8baca0852be1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1cbeb30e-64cf-4693-b853-4a0f3922fd9d",
   "metadata": {},
   "source": [
    "## 1b.4. Diagnostic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "d73996b4-27f2-48fa-946f-f483c9c42ac5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# select the subset of magview findings from diagnostic exams\n",
    "mag_diag = mag_df.loc[mag_df.desc.str.contains('diag', case=False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "02e9f0f0-9b13-4088-9f88-4de1acc0b0e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "magview diag\n",
      "Patients: 18368\n",
      "Exams: 27098\n",
      "Findings: 37587\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dataframe_stats(mag_diag, 'magview diag')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3a9de0b-869d-427a-9e1e-1ddc8fb875bc",
   "metadata": {},
   "source": [
    "## 1b.5. Screening BIRADS 0 and Diagnostic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "61cf2829-565d-4a14-8062-c471efcdd33f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge screen birads 0 cases with all diagnostic cases on empi_anon\n",
    "scr_col_list = list(scr_br0.columns)\n",
    "scr_diag_b0 = pd.merge(scr_br0, mag_diag, on='empi_anon', suffixes=[None, \"_dx\"])\n",
    "\n",
    "# exclude scr/diag side mismatches\n",
    "# after contralateral correction, all screening findings have L or R laterality\n",
    "# exclude cases where dx side != scr side, or when the dx side is \"B\" or \"NaN\"\n",
    "scr_diag_b0 = scr_diag_b0.loc[\n",
    "    (scr_diag_b0.side==scr_diag_b0.side_dx)\n",
    "    | (scr_diag_b0.side_dx==\"B\")\n",
    "    | (scr_diag_b0.side_dx.isna())\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "f81706cd-257c-4f78-b726-65d9e7d53b1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "magview screen/diag br0\n",
      "Patients: 9077\n",
      "Exams: 10185\n",
      "Findings: 28322\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dataframe_stats(scr_diag_b0, 'magview screen/diag br0')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d8d78c8-c406-40d7-b6cc-b2eaf3235ee0",
   "metadata": {},
   "source": [
    "We now have a dataframe containing all screening BIRADS 0 exams merged with *any* diagnostic exams for each patient. Most of these exams are irrelevant to one another though. How could we filter this dataframe to only contain valid BIRADS 0 screening exams with follow-up diagnostics?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45ade25e-7d18-4e05-a54d-0a3589a87920",
   "metadata": {},
   "source": [
    "### Pre-Merge:\n",
    "**Screening:**\n",
    "Screen Exam 1,\n",
    "Screen Exam 2,\n",
    "Screen Exam 3\n",
    "\n",
    "**Diagnostic:**\n",
    "Diag Exam 1,\n",
    "Diag Exam 2\n",
    "\n",
    "### Post-Merge:\n",
    "**Screening + Diagnostic:**\n",
    "\n",
    "Screen Exam 1 + Diag Exam 1\n",
    "\n",
    "Screen Exam 1 + Diag Exam 2\n",
    "\n",
    "Screen Exam 2 + Diag Exam 1\n",
    "\n",
    "Screen Exam 2 + Diag Exam 2\n",
    "\n",
    "Screen Exam 3 + Diag Exam 1\n",
    "\n",
    "Screen Exam 3 + Diag Exam 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26275344-925f-49cb-85c6-b2c6bf700877",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a52457cc-6882-4364-8f3b-da652b0f842e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "f7fc1e76-9125-490c-8850-94e611614640",
   "metadata": {},
   "outputs": [],
   "source": [
    "# retain subsequent diagnostic studies within 6 months\n",
    "MAX_DIAG_GAP_DAYS = 30 * 6 # 6 months/180 days\n",
    "\n",
    "# subtract our screening study date from our diagnostic study date to get the time between them\n",
    "scr_diag_b0[\"delta_date_dx\"] = (scr_diag_b0.study_date_anon_dx - scr_diag_b0.study_date_anon).dt.days\n",
    "# only retain those with a time delta greater than 0 days and less than 6 months\n",
    "scr_diag_filt_b0 = scr_diag_b0.loc[(scr_diag_b0.delta_date_dx > 0) & (scr_diag_b0.delta_date_dx <= MAX_DIAG_GAP_DAYS)]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91737af1-9ebb-4d92-8140-44e09640138e",
   "metadata": {},
   "source": [
    "> ## Question:\n",
    ">\n",
    "> **What does our dataframe now contain?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "e01cee05-5868-4db9-87e1-b8d16b0dd71c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "magview screen/diag br0 (after t delta filter)\n",
      "Patients: 8406\n",
      "Exams: 9072\n",
      "Findings: 17366\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dataframe_stats(scr_diag_filt_b0, 'magview screen/diag br0 (after t delta filter)')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41e44289-92b7-4951-b787-a29816609be5",
   "metadata": {},
   "source": [
    "## 1b.6. Screening BIRADS 0 > Diagnostic Path Severity 0/1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "a7971166-aa20-4549-a1ab-fab67582cea3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can now filter this dataframe to find our patients that had a path severity\n",
    "# of 0 or 1 assigned to their diagnostic exam\n",
    "# this will overlap with our other dataframe (of screening findings with a path severity of 0/1)\n",
    "# but we'll merge them and prevent any duplication\n",
    "scr_diag_ps01 = scr_diag_filt_b0.loc[scr_diag_filt_b0.path_severity_dx.isin([0.0, 1.0])].copy()\n",
    "\n",
    "# again we want to only retain findings with a laterality matching the relevant biopsy laterality\n",
    "scr_diag_ps01 = scr_diag_ps01.loc[(scr_diag_ps01.side_dx == scr_diag_ps01.bside_dx) | (scr_diag_ps01.bside_dx == 'B')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "eb36eae6-23cb-4fc2-a4a6-b3f96ed35fa9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "magview screen/diag path severity 0/1\n",
      "Patients: 1324\n",
      "Exams: 1331\n",
      "Findings: 4232\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dataframe_stats(scr_diag_ps01, 'magview screen/diag path severity 0/1')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9cc4980-23c1-460d-af52-5e3d83a08fe4",
   "metadata": {},
   "source": [
    "## 1b.7. Positive Findings (Cancer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "130d31aa-03af-465f-aa0a-b5a338a74246",
   "metadata": {},
   "outputs": [],
   "source": [
    "# concatenate the two cancer sets (screen ps 0/1 and scr+diag ps 0/1)\n",
    "pos_group = pd.concat([scr_ps01, scr_diag_ps01], axis=0)\n",
    "\n",
    "# drop any duplicates, we'll only apply this to a list of our normal magview columns\n",
    "# since we added some when we merged in the diagnostic findings\n",
    "pos_group.drop_duplicates(subset=scr_col_list, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "d500833b-a3c4-4dc1-8220-b6266e8b38b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "cancer findings\n",
      "Patients: 1536\n",
      "Exams: 1547\n",
      "Findings: 2570\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dataframe_stats(pos_group, 'cancer findings')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32fc3b47-81b0-40a5-9bb0-85a46f10923c",
   "metadata": {},
   "source": [
    "## 1b.8. Negative Findings (Non-Cancer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "2d743d11-2180-4994-ab7b-8325349aad52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "non-cancer findings\n",
      "Patients: 24995\n",
      "Exams: 63288\n",
      "Findings: 127079\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dataframe_stats(scr_not_ps01, 'non-cancer findings')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afb597fe-460b-4e21-86e7-22e616b6724e",
   "metadata": {},
   "source": [
    "## 1b.9 Exclude Findings with Positive Followup/No Negative Followup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "e4e0eec5-4390-455b-857c-0af1c32c261f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_4876/375617082.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  neg_group['valid_neg_followup'] = False\n",
      "100%|██████████| 63288/63288 [11:42<00:00, 90.07it/s] \n"
     ]
    }
   ],
   "source": [
    "# this code chunk takes a reeeaally long time to run so i pre-ran it\n",
    "# change this to True if you really want to run it\n",
    "\n",
    "RERUN_FOLLOWUP_CHECK = True\n",
    "\n",
    "if RERUN_FOLLOWUP_CHECK:\n",
    "    neg_group = scr_not_ps01\n",
    "    \n",
    "    duration_years = 2\n",
    "    duration_days = 365 * duration_years\n",
    "    \n",
    "    # initialize the 'valid_neg_followup' column\n",
    "    neg_group['valid_neg_followup'] = False\n",
    "    \n",
    "    # create a dictionary to store valid_neg_followup status for each acc_anon\n",
    "    valid_followup_dict = {}\n",
    "    \n",
    "    # group by 'acc_anon' and iterate through each group\n",
    "    for acc, group in tqdm(neg_group.groupby('acc_anon'), total=neg_group.acc_anon.nunique()):\n",
    "        # these should be identical for all findings in each group so we'll just treat the\n",
    "        # first index as representative\n",
    "        curr_empi = group['empi_anon'].iloc[0]\n",
    "        t0 = group['study_date_anon'].iloc[0]\n",
    "        \n",
    "        # get the subset of neg_group for the current patient\n",
    "        target_neg_group = neg_group.loc[neg_group.empi_anon == curr_empi, ['acc_anon', 'study_date_anon']].drop_duplicates()\n",
    "        # find the time delta between the negative followups and the current candidate exam date\n",
    "        target_neg_group['_followup_delta'] = (target_neg_group.study_date_anon - t0).dt.days\n",
    "    \n",
    "        # count the number of valid negative followups\n",
    "        n_followup_neg = target_neg_group[(target_neg_group._followup_delta > 0) & (target_neg_group._followup_delta <= duration_days)].shape[0]\n",
    "        \n",
    "        # Get the subset of pos_group for the current patient\n",
    "        target_pos_group = pos_group.loc[pos_group.empi_anon == curr_empi, ['acc_anon', 'study_date_anon']].drop_duplicates()\n",
    "        # if there are any positive cases from the patient, check if one is a disqualifying positive followup\n",
    "        if not target_pos_group.empty:\n",
    "            target_pos_group['_followup_delta'] = (target_pos_group.study_date_anon - t0).dt.days\n",
    "            n_followup_pos = target_pos_group[(target_pos_group._followup_delta > 0) & (target_pos_group._followup_delta <= duration_days)].shape[0]\n",
    "        else:\n",
    "            n_followup_pos = 0\n",
    "    \n",
    "        # mark the accession as valid if it has at least 1 valid negative followup and 0 valid positive followups\n",
    "        valid_followup_dict[acc] = (n_followup_neg > 0) & (n_followup_pos == 0)\n",
    "    \n",
    "    with open('datasets/neg_followups.pickle', 'wb') as handle:\n",
    "        pickle.dump(valid_followup_dict, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "# otherwise if we've already checked all our accessions we can just load the pickle\n",
    "else:\n",
    "    # load the saved pickle\n",
    "    with open('datasets/neg_followups.pickle', 'rb') as handle:\n",
    "        valid_followup_dict = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "c0801c6f-6b40-45cf-bec1-ec90fc9c1c04",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_4876/672287900.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  neg_group['valid_neg_followup'] = neg_group['acc_anon'].map(valid_followup_dict)\n"
     ]
    }
   ],
   "source": [
    "# update the 'valid_neg_followup' column in neg_group\n",
    "# initialize the column as false\n",
    "neg_group.loc[:, 'valid_neg_followup'] = False\n",
    "# then map our dictionary values over\n",
    "neg_group['valid_neg_followup'] = neg_group['acc_anon'].map(valid_followup_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "71812512-5d85-4310-81c4-57d61b5deff6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "negative w/ valid followup\n",
      "Patients: 11115\n",
      "Exams: 33929\n",
      "Findings: 67205\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_4876/1632784241.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  val_neg_group.loc[:, 'path_severity_dx'] = np.nan\n",
      "/tmp/ipykernel_4876/1632784241.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  val_neg_group.loc[:, 'asses_dx'] = np.nan\n",
      "/tmp/ipykernel_4876/1632784241.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  val_neg_group.loc[:, 'bside_dx'] = np.nan\n"
     ]
    }
   ],
   "source": [
    "val_neg_group = neg_group[neg_group.valid_neg_followup == True]\n",
    "val_neg_group.loc[:, 'path_severity_dx'] = np.nan\n",
    "val_neg_group.loc[:, 'asses_dx'] = np.nan\n",
    "val_neg_group.loc[:, 'bside_dx'] = np.nan\n",
    "dataframe_stats(val_neg_group, 'negative w/ valid followup')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c0eb3b2-b7ad-4b36-9861-a5971c15656c",
   "metadata": {},
   "source": [
    "## 1b.10. Excluding Positive Patients from the Negative Group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "97e40499-1ed2-4384-9df5-a8a78392a342",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "filtered negative\n",
      "Patients: 10944\n",
      "Exams: 33490\n",
      "Findings: 66381\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# get a list of empi in the positive set\n",
    "pos_empi_list = list(pos_group.empi_anon.unique())\n",
    "# exclude all positive empi from the negative set\n",
    "filt_neg_group = val_neg_group[~val_neg_group.empi_anon.isin(pos_empi_list)]\n",
    "    \n",
    "dataframe_stats(filt_neg_group, 'filtered negative')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e55c0bf-c933-4d7a-81fb-41b53ae31e8f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec8fb587-6853-42cb-ae16-d28803226532",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab7a74fa-8ca6-4e2a-a5dd-9474f88a47f5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "caf01f46-b875-4973-9464-c80c9a0e98d4",
   "metadata": {},
   "source": [
    "---\n",
    "## 1c Confirmed Normal vs Abnormal\n",
    "\n",
    "\n",
    "### Objectives: \n",
    "\n",
    "1. **Positive group**:\n",
    "    - Screening BIRADS 0 > Diagnostic BIRADS 3/4/5\n",
    "2. **Negative group**:\n",
    "    - Screening BIRADS 1/2\n",
    "    - Screening BIRADS 0 > Diagnostic BIRADS 1/2\n",
    "![1c](images/1c.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e8d3f93-ca33-4e9e-8565-977067cc8286",
   "metadata": {},
   "source": [
    "### How could we define these groups based on the examples we've seen? "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "837919d9-d162-4241-9496-094e7a92d679",
   "metadata": {},
   "source": [
    "---\n",
    "# 2. Image Selection\n",
    "For this demo we'll keep our image selection process very simple. We'll filter our metadata dataframe so it contains only 2D CC/MLO images.\n",
    "\n",
    "> ## Question\n",
    "> \n",
    "> **Why might we exclude other image types when training models?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "c4279df5-3282-4377-aceb-1dd2d576467a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# EMBED 2D (MLO and CC)\n",
    "meta_2d = meta_df.loc[(meta_df.FinalImageType==\"2D\") & (meta_df.ViewPosition.isin([\"MLO\", \"CC\"]))]\n",
    "\n",
    "# exclude special views (we don't really expect these during screening but it doesn't hurt to be safe)\n",
    "# why do we want to exclude these?\n",
    "meta_2d = meta_2d[meta_2d.spot_mag != 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "a997056b-32f8-476b-b089-0fcc6fe0cd20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "metadata 2d\n",
      "Patients: 31973\n",
      "Exams: 86011\n",
      "Images: 393286\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dataframe_stats(meta_2d, 'metadata 2d')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a355a08a-7529-4872-950e-81385b3cd524",
   "metadata": {},
   "source": [
    "---\n",
    "# 3. Magview/Metadata Merge\n",
    "Now that both our clinical and image samples have been defined, we can merge them together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "991e25a4-8c4a-479a-860b-4eb688021b13",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "a30e0f82-494f-4cf5-838c-a5cd4cc256bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_2d['empi_anon'] = pd.to_numeric(meta_2d['empi_anon'])\n",
    "meta_2d['acc_anon'] = pd.to_numeric(meta_2d['acc_anon'])\n",
    "\n",
    "mag_norm_df['empi_anon'] = pd.to_numeric(mag_norm_df['empi_anon'])\n",
    "mag_norm_df['acc_anon'] = pd.to_numeric(mag_norm_df['acc_anon'])\n",
    "\n",
    "mag_abnorm_df['empi_anon'] = pd.to_numeric(mag_abnorm_df['empi_anon'])\n",
    "mag_abnorm_df['acc_anon'] = pd.to_numeric(mag_abnorm_df['acc_anon'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "694b924c-f748-4d67-a7b9-7735c1d90a01",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "side\n",
       "R    33705\n",
       "L    33677\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mag_norm_df.side.value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0ca5be2-9312-4cff-9d4b-ccca5bbfd2f7",
   "metadata": {},
   "source": [
    "## 3.1. Merge Positive Group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "4790c071-0a34-435d-90be-825c9abc44b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge with metadata to get images\n",
    "scr_br0_meta = mag_abnorm_df.merge(meta_2d, on=[\"empi_anon\", \"acc_anon\"], how='left')\n",
    "# ensure we have no special views\n",
    "scr_br0_meta = scr_br0_meta[scr_br0_meta.spot_mag != 1.0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "af9afcfb-9520-45a6-993d-712358b3b9ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "side  ImageLateralityFinal\n",
       "R     R                       21438\n",
       "L     L                       21410\n",
       "      R                       21128\n",
       "R     L                       20790\n",
       "L     NaN                       324\n",
       "R     NaN                       283\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scr_br0_meta[['side', 'ImageLateralityFinal']].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80899952-1518-4f1d-a43c-4db1f5a38e3a",
   "metadata": {},
   "source": [
    "Since we previously applied a contralateral correction, all of our bilateral findings have been mapped to 2 unilateral findings (1 L and 1 R). Otherwise, if we still have findings with the laterality 'B' or 'NaN' we should only apply the following exclusion criteria:\n",
    "\n",
    "```python\n",
    "scr_br0_meta[~((scr_br0_meta.side == 'R') & (scr_br0_meta.ImageLateralityFinal == 'L')) &\\\n",
    "             ~((scr_br0_meta.side == 'L') & (scr_br0_meta.ImageLateralityFinal == 'R'))]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "321a8ff5-8eee-4a87-b12c-869600d1db2c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "side  ImageLateralityFinal\n",
       "R     R                       21438\n",
       "L     L                       21410\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we have no findings with 'B' or 'NaN' lateralities left, so we can simply apply the following\n",
    "scr_br0_meta = scr_br0_meta[scr_br0_meta.side == scr_br0_meta.ImageLateralityFinal]\n",
    "scr_br0_meta[['side', 'ImageLateralityFinal']].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "386ee222-3411-434d-ae09-ba6668997c30",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "29b64773-d7ef-4f2f-989c-a394c7a6e481",
   "metadata": {},
   "source": [
    "## 3.2. Merge Negative Group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "9f8832dd-7a11-4191-9d5a-e0a1b6b06801",
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge with metadata to get images\n",
    "scr_br12_meta = mag_norm_df.merge(meta_2d, on=[\"empi_anon\", \"acc_anon\"], how='left')\n",
    "# ensure we have no special views\n",
    "scr_br12_meta = scr_br12_meta[scr_br12_meta.spot_mag != 1.0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "0d821fff-5e76-4d3f-8b54-681e4c6ca1a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "side  ImageLateralityFinal\n",
       "R     R                       79258\n",
       "L     L                       78564\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we have no findings with 'B' or 'NaN' lateralities left, so we can simply apply the following\n",
    "scr_br12_meta = scr_br12_meta[scr_br12_meta.side == scr_br12_meta.ImageLateralityFinal]\n",
    "scr_br12_meta[['side', 'ImageLateralityFinal']].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7eb50308-24be-41f1-bcf7-f50c92a85276",
   "metadata": {},
   "source": [
    "## 3.3. Export Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "da8cfcaf-9035-4505-b740-d329cf30fb50",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "'break' outside loop (1775773440.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[90], line 1\u001b[0;36m\u001b[0m\n\u001b[0;31m    break\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m 'break' outside loop\n"
     ]
    }
   ],
   "source": [
    "break\n",
    "scr_br0_meta.to_csv('datasets/POSITIVE_BR0_GROUP.csv', index=False)\n",
    "scr_br12_meta.to_csv('datasets/NEGATIVE_BR12_GROUP_FULL.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7ec8c95-680d-4a0d-875e-af1d9252c97f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d669edd2-5b8f-413e-b38a-c66d2462b7e0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b640881f-682a-4af0-91fb-8d90adb8e2a8",
   "metadata": {},
   "source": [
    "---\n",
    "# 4. Sampling\n",
    "> We'll load in our normal vs abnormal dataframes for the remainder of the notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "bea224fb-077d-4cf4-86f4-b1073bd7aa20",
   "metadata": {},
   "outputs": [],
   "source": [
    "scr_br0_meta = pd.read_csv('datasets/POSITIVE_BR0_GROUP.csv')\n",
    "scr_br12_meta = pd.read_csv('datasets/NEGATIVE_BR12_GROUP_FULL.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed14350a-7f72-4211-8aa0-62aab664a66b",
   "metadata": {},
   "source": [
    "## 4.1. (Optionally) Randomly Sample 1 Exam per Patient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "19e4b999-2e23-4bcb-bc82-7a11026b9356",
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_random_exam(group, seed=13, n=1):\n",
    "    return random.Random(seed).sample(group.acc_anon.unique().tolist(), n)\n",
    "\n",
    "def select_exam_per_patient(df):\n",
    "    \"\"\"\n",
    "    function to randomly select n accessions associated with each EMPI and exclude the rest\n",
    "    \"\"\"\n",
    "    # group by 'empi_anon' and apply the function\n",
    "    acc_list = [i[0] for i in df.groupby('empi_anon').apply(select_random_exam).tolist()]\n",
    "\n",
    "    # exclude accs not found in the acc list\n",
    "    filt_df = df[df.acc_anon.isin(acc_list)]\n",
    "    return filt_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "7531dd02-3e7b-43ba-918b-70b7280f19e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "positive (birads 0) sample (1 exam per patient)\n",
      "Patients: 11983\n",
      "Exams: 11983\n",
      "Images: 33600\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_4876/598747432.py:9: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  acc_list = [i[0] for i in df.groupby('empi_anon').apply(select_random_exam).tolist()]\n"
     ]
    }
   ],
   "source": [
    "scr_br0_meta_filt = select_exam_per_patient(scr_br0_meta)\n",
    "dataframe_stats(scr_br0_meta_filt, 'positive (birads 0) sample (1 exam per patient)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "dfff1c7d-90f9-45fd-a02f-2e05dc500776",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "negative (birads 1/2) sample (1 exam per patient)\n",
      "Patients: 12607\n",
      "Exams: 12607\n",
      "Images: 60832\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_4876/598747432.py:9: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  acc_list = [i[0] for i in df.groupby('empi_anon').apply(select_random_exam).tolist()]\n"
     ]
    }
   ],
   "source": [
    "scr_br12_meta_filt = select_exam_per_patient(scr_br12_meta)\n",
    "dataframe_stats(scr_br12_meta_filt, 'negative (birads 1/2) sample (1 exam per patient)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3bba63f-310c-49fa-b700-e0c3ec3c4c4c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "59f53ea6-f2e4-48d9-99d0-041100ae2126",
   "metadata": {},
   "outputs": [],
   "source": [
    "scr_br0_meta_filt = pd.read_csv('./datasets/POSITIVE_BR0_GROUP.csv')\n",
    "scr_br12_meta_filt = pd.read_csv('./datasets/NEGATIVE_BR12_GROUP_FULL.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c85055d7-86a7-4979-98ff-07595dfe9b74",
   "metadata": {},
   "source": [
    "## 4.2. Dataset Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "501253ce-ecc0-4cc2-a032-e24516d4b454",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bin_ethnicity(df):\n",
    "    # define our ethnicity mapping dict\n",
    "    ethnicity_map_dict = {\n",
    "        'Non-Hispanic or Latino': 'Not Hispanic or Latino',\n",
    "        'Non-Hispanic~Unknown': 'Not Hispanic or Latino',\n",
    "        'Unknown~Non-Hispanic': 'Not Hispanic or Latino',\n",
    "        'Hispanic or Latino': 'Hispanic or Latino', \n",
    "        'Unknown~Hispanic': 'Hispanic or Latino'\n",
    "    }\n",
    "    # strip leading/trailing whitespace from the 'ETHNIC_GROUP_DESC' column\n",
    "    df['ETHNIC_GROUP_DESC'].str.strip()\n",
    "    \n",
    "    # initialize the new column as 'Unknown' then map our ethnicity dict onto it\n",
    "    df['Ethnicity'] = 'Unknown'\n",
    "    df['Ethnicity'] = df['ETHNIC_GROUP_DESC'].map(ethnicity_map_dict)\n",
    "    return df\n",
    "\n",
    "def bin_race(df):\n",
    "    # define our race mapping dict\n",
    "    race_map_dict = {\n",
    "        'African American  or Black': 'Black',\n",
    "        'Caucasian or White': 'White',\n",
    "        'Asian': 'Asian',\n",
    "        'Native Hawaiian or Other Pacific Islander': 'Other', \n",
    "        'Multiple': 'Other',\n",
    "        'American Indian or Alaskan Native': 'Other',\n",
    "    }\n",
    "    # strip leading/trailing whitespace from the 'ETHNICITY_DESC' column\n",
    "    df['ETHNICITY_DESC'].str.strip()\n",
    "    \n",
    "    # initialize the new column as 'Unknown' then map our race dict onto it\n",
    "    df['Race'] = 'Unknown'\n",
    "    df['Race'] = df['ETHNICITY_DESC'].map(race_map_dict)\n",
    "    return df\n",
    "\n",
    "scr_br0_meta_filt['Label'] = 'Positive'\n",
    "scr_br0_meta_filt = bin_ethnicity(scr_br0_meta_filt)\n",
    "scr_br0_meta_filt = bin_race(scr_br0_meta_filt)\n",
    "\n",
    "scr_br12_meta_filt['Label'] = 'Negative'\n",
    "scr_br12_meta_filt = bin_ethnicity(scr_br12_meta_filt)\n",
    "scr_br12_meta_filt = bin_race(scr_br12_meta_filt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "f52a0359-6fcb-4c88-8320-3d3833fd1002",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_findings(row):\n",
    "    # output imaging features coded as either 0: absent or 1: present\n",
    "    findings_dict = {\n",
    "        'mass': 0,\n",
    "        'asymmetry': 0,\n",
    "        'arch_distortion': 0,\n",
    "        'calcification': 0\n",
    "    }\n",
    "\n",
    "    if (row['massshape'] in ['G', 'R', 'O', 'X', 'N', 'Y', 'D', 'L']) or\\\n",
    "    (row['massmargin'] in ['D', 'U', 'M', 'I', 'S']) or\\\n",
    "    (row['massdens'] in ['+', '-', '=']):\n",
    "        findings_dict['mass'] = 1\n",
    "\n",
    "    if row['massshape'] in ['T', 'B', 'S', 'F', 'V']:\n",
    "        findings_dict['asymmetry'] = 1\n",
    "\n",
    "    if row['massshape']in ['Q', 'A']:\n",
    "        findings_dict['arch_distortion'] = 1\n",
    "\n",
    "    if (row['calcdistri'] is not np.nan) or\\\n",
    "    (row['calcfind'] is not np.nan) or\\\n",
    "    (row['calcnumber'] != 0):\n",
    "        findings_dict['calcification'] = 1\n",
    "\n",
    "    return findings_dict\n",
    "\n",
    "scr_br0_meta_filt[['mass', 'asymmetry', 'arch_distortion', 'calcification']] = scr_br0_meta_filt.apply(\n",
    "    extract_findings, \n",
    "    axis='columns', \n",
    "    result_type='expand'\n",
    ")\n",
    "scr_br12_meta_filt[['mass', 'asymmetry', 'arch_distortion', 'calcification']] = scr_br12_meta_filt.apply(\n",
    "    extract_findings, \n",
    "    axis='columns', \n",
    "    result_type='expand'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "30e8d4de-8dbe-409f-bea1-7da44a4067bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bin_feature(df, feature, bin_interval_dict):\n",
    "    # get binned feature name\n",
    "    binned_feature = f\"{feature}_bins\"\n",
    "\n",
    "    # initialize binned feature\n",
    "    df[binned_feature] = 'nan'\n",
    "\n",
    "    # iterate over intervals defined in the interval dictionary\n",
    "    for level_name, (interval_min, interval_max) in bin_interval_dict.items():\n",
    "        df_mask = (df[feature] >= interval_min) & (df[feature] < interval_max)\n",
    "        df.loc[df_mask, binned_feature] = level_name\n",
    "\n",
    "    return df\n",
    "\n",
    "bin_intervals = {\n",
    "    '<40': (0, 40),\n",
    "    '40-60': (40, 60),\n",
    "    '>=60': (60, 200)\n",
    "}\n",
    "\n",
    "scr_br0_meta_filt.dropna(subset='age_at_study', inplace=True)\n",
    "scr_br12_meta_filt.dropna(subset='age_at_study', inplace=True)\n",
    "\n",
    "scr_br0_meta_filt = bin_feature(scr_br0_meta_filt, 'age_at_study', bin_intervals)\n",
    "scr_br12_meta_filt = bin_feature(scr_br12_meta_filt, 'age_at_study', bin_intervals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "673b1630-198d-43a6-94be-fea016626cb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/tljh/user/envs/pandas/lib/python3.11/site-packages/tableone/preprocessors.py:123: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '[3.0 3.0 2.0 ... 3.0 3.0 3.0]' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  df.loc[:, column] = df[column].fillna(null_value)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "╒═════════════════════════════════╤════════════════════════╤═══════════╤═══════════════╤════════════════╤══════════════╕\n",
      "│                                 │                        │ Missing   │ Overall       │ Negative       │ Positive     │\n",
      "╞═════════════════════════════════╪════════════════════════╪═══════════╪═══════════════╪════════════════╪══════════════╡\n",
      "│ n                               │                        │           │ 200033        │ 157301         │ 42732        │\n",
      "├─────────────────────────────────┼────────────────────────┼───────────┼───────────────┼────────────────┼──────────────┤\n",
      "│ Tissue Density, n (%)           │ 1.0                    │           │ 24917 (12.5)  │ 21617 (13.7)   │ 3300 (7.7)   │\n",
      "├─────────────────────────────────┼────────────────────────┼───────────┼───────────────┼────────────────┼──────────────┤\n",
      "│                                 │ 2.0                    │           │ 87161 (43.6)  │ 69892 (44.4)   │ 17269 (40.4) │\n",
      "├─────────────────────────────────┼────────────────────────┼───────────┼───────────────┼────────────────┼──────────────┤\n",
      "│                                 │ 3.0                    │           │ 77648 (38.8)  │ 57764 (36.7)   │ 19884 (46.5) │\n",
      "├─────────────────────────────────┼────────────────────────┼───────────┼───────────────┼────────────────┼──────────────┤\n",
      "│                                 │ 4.0                    │           │ 9705 (4.9)    │ 7580 (4.8)     │ 2125 (5.0)   │\n",
      "├─────────────────────────────────┼────────────────────────┼───────────┼───────────────┼────────────────┼──────────────┤\n",
      "│                                 │ 5.0                    │           │ 20 (0.0)      │ 20 (0.0)       │              │\n",
      "├─────────────────────────────────┼────────────────────────┼───────────┼───────────────┼────────────────┼──────────────┤\n",
      "│                                 │ None                   │           │ 582 (0.3)     │ 428 (0.3)      │ 154 (0.4)    │\n",
      "├─────────────────────────────────┼────────────────────────┼───────────┼───────────────┼────────────────┼──────────────┤\n",
      "│ Race, n (%)                     │ Asian                  │           │ 11632 (5.8)   │ 8979 (5.7)     │ 2653 (6.2)   │\n",
      "├─────────────────────────────────┼────────────────────────┼───────────┼───────────────┼────────────────┼──────────────┤\n",
      "│                                 │ Black                  │           │ 86418 (43.2)  │ 66693 (42.4)   │ 19725 (46.2) │\n",
      "├─────────────────────────────────┼────────────────────────┼───────────┼───────────────┼────────────────┼──────────────┤\n",
      "│                                 │ None                   │           │ 14259 (7.1)   │ 11070 (7.0)    │ 3189 (7.5)   │\n",
      "├─────────────────────────────────┼────────────────────────┼───────────┼───────────────┼────────────────┼──────────────┤\n",
      "│                                 │ Other                  │           │ 2354 (1.2)    │ 1646 (1.0)     │ 708 (1.7)    │\n",
      "├─────────────────────────────────┼────────────────────────┼───────────┼───────────────┼────────────────┼──────────────┤\n",
      "│                                 │ White                  │           │ 85370 (42.7)  │ 68913 (43.8)   │ 16457 (38.5) │\n",
      "├─────────────────────────────────┼────────────────────────┼───────────┼───────────────┼────────────────┼──────────────┤\n",
      "│ Ethnicity, n (%)                │ Hispanic or Latino     │           │ 8734 (4.4)    │ 6613 (4.2)     │ 2121 (5.0)   │\n",
      "├─────────────────────────────────┼────────────────────────┼───────────┼───────────────┼────────────────┼──────────────┤\n",
      "│                                 │ None                   │           │ 30133 (15.1)  │ 24209 (15.4)   │ 5924 (13.9)  │\n",
      "├─────────────────────────────────┼────────────────────────┼───────────┼───────────────┼────────────────┼──────────────┤\n",
      "│                                 │ Not Hispanic or Latino │           │ 161166 (80.6) │ 126479 (80.4)  │ 34687 (81.2) │\n",
      "├─────────────────────────────────┼────────────────────────┼───────────┼───────────────┼────────────────┼──────────────┤\n",
      "│ Age Bins, n (%)                 │ 40-60                  │           │ 101005 (50.5) │ 76761 (48.8)   │ 24244 (56.7) │\n",
      "├─────────────────────────────────┼────────────────────────┼───────────┼───────────────┼────────────────┼──────────────┤\n",
      "│                                 │ <40                    │           │ 3405 (1.7)    │ 2392 (1.5)     │ 1013 (2.4)   │\n",
      "├─────────────────────────────────┼────────────────────────┼───────────┼───────────────┼────────────────┼──────────────┤\n",
      "│                                 │ >=60                   │           │ 95623 (47.8)  │ 78148 (49.7)   │ 17475 (40.9) │\n",
      "├─────────────────────────────────┼────────────────────────┼───────────┼───────────────┼────────────────┼──────────────┤\n",
      "│ Mass, n (%)                     │ 0                      │           │ 191536 (95.8) │ 154747 (98.4)  │ 36789 (86.1) │\n",
      "├─────────────────────────────────┼────────────────────────┼───────────┼───────────────┼────────────────┼──────────────┤\n",
      "│                                 │ 1                      │           │ 8497 (4.2)    │ 2554 (1.6)     │ 5943 (13.9)  │\n",
      "├─────────────────────────────────┼────────────────────────┼───────────┼───────────────┼────────────────┼──────────────┤\n",
      "│ Asymmetry, n (%)                │ 0                      │           │ 179786 (89.9) │ 156164 (99.3)  │ 23622 (55.3) │\n",
      "├─────────────────────────────────┼────────────────────────┼───────────┼───────────────┼────────────────┼──────────────┤\n",
      "│                                 │ 1                      │           │ 20247 (10.1)  │ 1137 (0.7)     │ 19110 (44.7) │\n",
      "├─────────────────────────────────┼────────────────────────┼───────────┼───────────────┼────────────────┼──────────────┤\n",
      "│ Architectural Distortion, n (%) │ 0                      │           │ 197499 (98.7) │ 157275 (100.0) │ 40224 (94.1) │\n",
      "├─────────────────────────────────┼────────────────────────┼───────────┼───────────────┼────────────────┼──────────────┤\n",
      "│                                 │ 1                      │           │ 2534 (1.3)    │ 26 (0.0)       │ 2508 (5.9)   │\n",
      "├─────────────────────────────────┼────────────────────────┼───────────┼───────────────┼────────────────┼──────────────┤\n",
      "│ Calcification, n (%)            │ 0                      │           │ 186490 (93.2) │ 154351 (98.1)  │ 32139 (75.2) │\n",
      "├─────────────────────────────────┼────────────────────────┼───────────┼───────────────┼────────────────┼──────────────┤\n",
      "│                                 │ 1                      │           │ 13543 (6.8)   │ 2950 (1.9)     │ 10593 (24.8) │\n",
      "╘═════════════════════════════════╧════════════════════════╧═══════════╧═══════════════╧════════════════╧══════════════╛\n"
     ]
    }
   ],
   "source": [
    "merged_df = pd.concat([scr_br0_meta_filt, scr_br12_meta_filt])\n",
    "\n",
    "column_list = ['Label', 'tissueden', 'Race', 'Ethnicity', 'age_at_study_bins', 'mass', 'asymmetry', 'arch_distortion', 'calcification']\n",
    "rename_dict = {\n",
    "    'tissueden': 'Tissue Density', \n",
    "    'mass': 'Mass', \n",
    "    'asymmetry': 'Asymmetry', \n",
    "    'arch_distortion': 'Architectural Distortion',\n",
    "    'calcification': 'Calcification',\n",
    "    'age_at_study_bins': 'Age Bins'\n",
    "}\n",
    "\n",
    "mytable = TableOne(\n",
    "    merged_df.reset_index(), columns=column_list, \n",
    "    categorical=['Race', 'Ethnicity', 'age_at_study_bins', 'tissueden', 'mass', 'asymmetry', 'arch_distortion', 'calcification'], \n",
    "    groupby='Label', \n",
    "    rename=rename_dict, \n",
    "    pval=False\n",
    ")\n",
    "print(mytable.tabulate(tablefmt=\"fancy_grid\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3578e37-ef23-43bc-91b7-bd6c558344c1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e0b3530d-e4d9-44e6-969c-2416b71ad4ec",
   "metadata": {},
   "source": [
    "## 4.3. Basic Undersampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "7213596b-60e7-4e3f-a0ff-ce98a5aeaa66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "positive images: 42732 (21.4%)\n",
      "negative images: 157301 (78.6%)\n",
      "\n",
      "positive exams: 13152 (28.7%)\n",
      "negative exams: 32607 (71.3%)\n"
     ]
    }
   ],
   "source": [
    "n_pos_images = len(scr_br0_meta_filt)\n",
    "n_neg_images = len(scr_br12_meta_filt)\n",
    "print(f'positive images: {n_pos_images} ({(n_pos_images /(n_pos_images + n_neg_images)) * 100:.1f}%)')\n",
    "print(f'negative images: {n_neg_images} ({(n_neg_images /(n_pos_images + n_neg_images)) * 100:.1f}%)\\n')\n",
    "\n",
    "n_pos_exams = scr_br0_meta_filt.acc_anon.nunique()\n",
    "n_neg_exams = scr_br12_meta_filt.acc_anon.nunique()\n",
    "print(f'positive exams: {n_pos_exams} ({(n_pos_exams /(n_pos_exams + n_neg_exams)) * 100:.1f}%)')\n",
    "print(f'negative exams: {n_neg_exams} ({(n_neg_exams /(n_pos_exams + n_neg_exams)) * 100:.1f}%)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b801bdbc-8367-4d47-9556-6e4357dd12df",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b3adf508-48a8-4101-bde8-a03becb2d78e",
   "metadata": {},
   "source": [
    "We've got a fair class balance here already (21% / 79%). If we had a heavily imbalanced dataset (e.g. 5% / 95%) we might choose to artificially undersample our majority class to make training easier. Other strategies to deal with heavily imbalanced data include synthetic data generation, loss function weighting, and alternate loss functions (such as focal loss: https://arxiv.org/abs/1708.02002).\n",
    "\n",
    "> ## Question\n",
    "> \n",
    "> **How would artificially rebalancing the classes of our test set affect the internal/external validity of the results?**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7de1a57f-92ca-4b21-8829-96342314c016",
   "metadata": {},
   "source": [
    "For now, we'll undersample both our positive and negative sets to speed up our model training. We'll do this while preserving our initial class balance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "4a169334-eaef-424b-9771-e85f6cfa6b24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n pos to sample: 5000\n",
      "n neg to sample: 12396\n"
     ]
    }
   ],
   "source": [
    "# seed our random number generator for reproducibility\n",
    "SEED = 63419\n",
    "random_generator = random.Random(SEED)\n",
    "\n",
    "# we'll select 5_000 exams/patients from our positive dataset then use that to determine how many\n",
    "# negative exams to sample\n",
    "n_pos_sample = 5_000\n",
    "\n",
    "n_neg_scale_factor = n_neg_exams / n_pos_exams\n",
    "n_neg_sample = int(n_pos_sample * n_neg_scale_factor)\n",
    "\n",
    "print('n pos to sample:', n_pos_sample)\n",
    "print('n neg to sample:', n_neg_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "08452ddf-c09a-4828-a896-3cfd53d75088",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get a list of all positive accessions\n",
    "total_pos_acc_list = list(scr_br0_meta_filt.acc_anon.unique())\n",
    "# randomly sample n_pos_sample of them, then filter the dataframe to get the subset\n",
    "# corresponding to the selected accessions\n",
    "sample_pos_acc_list = random_generator.sample(total_pos_acc_list, n_pos_sample)\n",
    "pos_sample = scr_br0_meta_filt[scr_br0_meta_filt.acc_anon.isin(sample_pos_acc_list)]\n",
    "\n",
    "# get a list of all negative accessions\n",
    "total_neg_acc_list = list(scr_br12_meta_filt.acc_anon.unique())\n",
    "# randomly sample n_neg_sample of them, then filter the dataframe to get the subset\n",
    "# corresponding to the selected accessions\n",
    "sample_neg_acc_list = random_generator.sample(total_neg_acc_list, n_neg_sample)\n",
    "neg_sample = scr_br12_meta_filt[scr_br12_meta_filt.acc_anon.isin(sample_neg_acc_list)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "85b669e0-9748-4505-865f-9cb5ad47956d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "positive images: 16310 (21.5%)\n",
      "negative images: 59648 (78.5%)\n",
      "\n",
      "positive exams: 5000 (28.7%)\n",
      "negative exams: 12396 (71.3%)\n"
     ]
    }
   ],
   "source": [
    "n_pos_images = len(pos_sample)\n",
    "n_neg_images = len(neg_sample)\n",
    "print(f'positive images: {n_pos_images} ({(n_pos_images /(n_pos_images + n_neg_images)) * 100:.1f}%)')\n",
    "print(f'negative images: {n_neg_images} ({(n_neg_images /(n_pos_images + n_neg_images)) * 100:.1f}%)\\n')\n",
    "\n",
    "n_pos_exams = pos_sample.acc_anon.nunique()\n",
    "n_neg_exams = neg_sample.acc_anon.nunique()\n",
    "print(f'positive exams: {n_pos_exams} ({(n_pos_exams /(n_pos_exams + n_neg_exams)) * 100:.1f}%)')\n",
    "print(f'negative exams: {n_neg_exams} ({(n_neg_exams /(n_pos_exams + n_neg_exams)) * 100:.1f}%)')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b5c95e7-00a7-49da-aea0-b626d726acfe",
   "metadata": {},
   "source": [
    "Since we didn't stratify our sampled accessions by tissue density, our sample distributions might be significantly different. In some cases this can function as a confounder during training and discourage generalizeable learning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "544c2f25-2f49-4339-aa97-b7bdbec3d626",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/tljh/user/envs/pandas/lib/python3.11/site-packages/tableone/preprocessors.py:123: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '[2.0 2.0 2.0 ... 3.0 3.0 3.0]' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  df.loc[:, column] = df[column].fillna(null_value)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "╒═════════════════════════════════╤════════════════════════╤═══════════╤══════════════╤═══════════════╤══════════════╕\n",
      "│                                 │                        │ Missing   │ Overall      │ Negative      │ Positive     │\n",
      "╞═════════════════════════════════╪════════════════════════╪═══════════╪══════════════╪═══════════════╪══════════════╡\n",
      "│ n                               │                        │           │ 75958        │ 59648         │ 16310        │\n",
      "├─────────────────────────────────┼────────────────────────┼───────────┼──────────────┼───────────────┼──────────────┤\n",
      "│ Tissue Density, n (%)           │ 1.0                    │           │ 9665 (12.7)  │ 8447 (14.2)   │ 1218 (7.5)   │\n",
      "├─────────────────────────────────┼────────────────────────┼───────────┼──────────────┼───────────────┼──────────────┤\n",
      "│                                 │ 2.0                    │           │ 32935 (43.4) │ 26247 (44.0)  │ 6688 (41.0)  │\n",
      "├─────────────────────────────────┼────────────────────────┼───────────┼──────────────┼───────────────┼──────────────┤\n",
      "│                                 │ 3.0                    │           │ 29385 (38.7) │ 21854 (36.6)  │ 7531 (46.2)  │\n",
      "├─────────────────────────────────┼────────────────────────┼───────────┼──────────────┼───────────────┼──────────────┤\n",
      "│                                 │ 4.0                    │           │ 3719 (4.9)   │ 2901 (4.9)    │ 818 (5.0)    │\n",
      "├─────────────────────────────────┼────────────────────────┼───────────┼──────────────┼───────────────┼──────────────┤\n",
      "│                                 │ 5.0                    │           │ 8 (0.0)      │ 8 (0.0)       │              │\n",
      "├─────────────────────────────────┼────────────────────────┼───────────┼──────────────┼───────────────┼──────────────┤\n",
      "│                                 │ None                   │           │ 246 (0.3)    │ 191 (0.3)     │ 55 (0.3)     │\n",
      "├─────────────────────────────────┼────────────────────────┼───────────┼──────────────┼───────────────┼──────────────┤\n",
      "│ Race, n (%)                     │ Asian                  │           │ 4284 (5.6)   │ 3331 (5.6)    │ 953 (5.8)    │\n",
      "├─────────────────────────────────┼────────────────────────┼───────────┼──────────────┼───────────────┼──────────────┤\n",
      "│                                 │ Black                  │           │ 32940 (43.4) │ 25399 (42.6)  │ 7541 (46.2)  │\n",
      "├─────────────────────────────────┼────────────────────────┼───────────┼──────────────┼───────────────┼──────────────┤\n",
      "│                                 │ None                   │           │ 5408 (7.1)   │ 4132 (6.9)    │ 1276 (7.8)   │\n",
      "├─────────────────────────────────┼────────────────────────┼───────────┼──────────────┼───────────────┼──────────────┤\n",
      "│                                 │ Other                  │           │ 905 (1.2)    │ 594 (1.0)     │ 311 (1.9)    │\n",
      "├─────────────────────────────────┼────────────────────────┼───────────┼──────────────┼───────────────┼──────────────┤\n",
      "│                                 │ White                  │           │ 32421 (42.7) │ 26192 (43.9)  │ 6229 (38.2)  │\n",
      "├─────────────────────────────────┼────────────────────────┼───────────┼──────────────┼───────────────┼──────────────┤\n",
      "│ Ethnicity, n (%)                │ Hispanic or Latino     │           │ 3290 (4.3)   │ 2423 (4.1)    │ 867 (5.3)    │\n",
      "├─────────────────────────────────┼────────────────────────┼───────────┼──────────────┼───────────────┼──────────────┤\n",
      "│                                 │ None                   │           │ 11272 (14.8) │ 8958 (15.0)   │ 2314 (14.2)  │\n",
      "├─────────────────────────────────┼────────────────────────┼───────────┼──────────────┼───────────────┼──────────────┤\n",
      "│                                 │ Not Hispanic or Latino │           │ 61396 (80.8) │ 48267 (80.9)  │ 13129 (80.5) │\n",
      "├─────────────────────────────────┼────────────────────────┼───────────┼──────────────┼───────────────┼──────────────┤\n",
      "│ Age Bins, n (%)                 │ 40-60                  │           │ 38316 (50.4) │ 28929 (48.5)  │ 9387 (57.6)  │\n",
      "├─────────────────────────────────┼────────────────────────┼───────────┼──────────────┼───────────────┼──────────────┤\n",
      "│                                 │ <40                    │           │ 1253 (1.6)   │ 880 (1.5)     │ 373 (2.3)    │\n",
      "├─────────────────────────────────┼────────────────────────┼───────────┼──────────────┼───────────────┼──────────────┤\n",
      "│                                 │ >=60                   │           │ 36389 (47.9) │ 29839 (50.0)  │ 6550 (40.2)  │\n",
      "├─────────────────────────────────┼────────────────────────┼───────────┼──────────────┼───────────────┼──────────────┤\n",
      "│ Mass, n (%)                     │ 0                      │           │ 72803 (95.8) │ 58633 (98.3)  │ 14170 (86.9) │\n",
      "├─────────────────────────────────┼────────────────────────┼───────────┼──────────────┼───────────────┼──────────────┤\n",
      "│                                 │ 1                      │           │ 3155 (4.2)   │ 1015 (1.7)    │ 2140 (13.1)  │\n",
      "├─────────────────────────────────┼────────────────────────┼───────────┼──────────────┼───────────────┼──────────────┤\n",
      "│ Asymmetry, n (%)                │ 0                      │           │ 68276 (89.9) │ 59233 (99.3)  │ 9043 (55.4)  │\n",
      "├─────────────────────────────────┼────────────────────────┼───────────┼──────────────┼───────────────┼──────────────┤\n",
      "│                                 │ 1                      │           │ 7682 (10.1)  │ 415 (0.7)     │ 7267 (44.6)  │\n",
      "├─────────────────────────────────┼────────────────────────┼───────────┼──────────────┼───────────────┼──────────────┤\n",
      "│ Architectural Distortion, n (%) │ 0                      │           │ 74940 (98.7) │ 59635 (100.0) │ 15305 (93.8) │\n",
      "├─────────────────────────────────┼────────────────────────┼───────────┼──────────────┼───────────────┼──────────────┤\n",
      "│                                 │ 1                      │           │ 1018 (1.3)   │ 13 (0.0)      │ 1005 (6.2)   │\n",
      "├─────────────────────────────────┼────────────────────────┼───────────┼──────────────┼───────────────┼──────────────┤\n",
      "│ Calcification, n (%)            │ 0                      │           │ 70794 (93.2) │ 58544 (98.1)  │ 12250 (75.1) │\n",
      "├─────────────────────────────────┼────────────────────────┼───────────┼──────────────┼───────────────┼──────────────┤\n",
      "│                                 │ 1                      │           │ 5164 (6.8)   │ 1104 (1.9)    │ 4060 (24.9)  │\n",
      "╘═════════════════════════════════╧════════════════════════╧═══════════╧══════════════╧═══════════════╧══════════════╛\n"
     ]
    }
   ],
   "source": [
    "merged_df = pd.concat([pos_sample, neg_sample])\n",
    "\n",
    "column_list = ['Label', 'tissueden', 'Race', 'Ethnicity', 'age_at_study_bins', 'mass', 'asymmetry', 'arch_distortion', 'calcification']\n",
    "rename_dict = {\n",
    "    'tissueden': 'Tissue Density', \n",
    "    'mass': 'Mass', \n",
    "    'asymmetry': 'Asymmetry', \n",
    "    'arch_distortion': 'Architectural Distortion',\n",
    "    'calcification': 'Calcification',\n",
    "    'age_at_study_bins': 'Age Bins'\n",
    "}\n",
    "\n",
    "mytable = TableOne(\n",
    "    merged_df.reset_index(), columns=column_list, \n",
    "    categorical=['Race', 'Ethnicity', 'age_at_study_bins', 'tissueden', 'mass', 'asymmetry', 'arch_distortion', 'calcification'], \n",
    "    groupby='Label', \n",
    "    rename=rename_dict, \n",
    "    pval=False\n",
    ")\n",
    "print(mytable.tabulate(tablefmt=\"fancy_grid\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faa0d815-4a6a-40b5-b454-de1743bb5a9a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fadb703e-3d5e-41fe-9896-c4fcbe1de78e",
   "metadata": {},
   "source": [
    "### 4.4. Balanced Undersampling\n",
    "\n",
    "\n",
    "> ## Question\n",
    ">\n",
    "> **What is shortcut learning?**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cadb3f59-cc03-47ae-9c92-0914fff9ebdb",
   "metadata": {},
   "source": [
    "![shortcut_learning](images/shortcut_learning.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "0eb07290-0670-40a2-90d5-7c8cb44a7b17",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "import itertools\n",
    "\n",
    "\n",
    "class DataBalancer:\n",
    "    def __init__(self, seed: int = 13, verbose: bool = False):\n",
    "        # set the seed\n",
    "        self.seed = seed\n",
    "\n",
    "        # initialize variables as none\n",
    "        self.reference_df = None\n",
    "        self.target_df = None\n",
    "        self.feature_list = None\n",
    "        self.target_ratio = None\n",
    "        self.level_dict = None\n",
    "        self.slice_list = None\n",
    "        self.verbose = verbose\n",
    "\n",
    "    def set_reference(self, reference_df):\n",
    "        self.reference_df = reference_df\n",
    "        dataframe_stats(self.reference_df, \"reference dataframe:\")\n",
    "\n",
    "    def set_target(self, target_df):\n",
    "        self.target_df = target_df\n",
    "        dataframe_stats(self.target_df, \"target dataframe:\")\n",
    "\n",
    "    def set_feature_list(self, feature_list):\n",
    "        self.feature_list = feature_list\n",
    "        print(f\"balancing distribution based on {', '.join(self.feature_list)}\\n\")\n",
    "\n",
    "    def set_balance(self, target_ratio, reference_ratio=1):\n",
    "        # ref and target ratio should be equal for 50/50 balancing\n",
    "        # normalize the target ratio so the reference is treated as 1\n",
    "        # and the ratio is 1:target_ratio \n",
    "        self.target_ratio = target_ratio / reference_ratio\n",
    "        # print(f\"balancing data with 1.00 : {self.target_ratio:.2f} ratio\\n\")\n",
    "\n",
    "    def get_unique_levels(self):\n",
    "        assert self.reference_df is not None, \"please select a reference dataframe with self.set_reference() first !\"\n",
    "        assert self.feature_list is not None, \"please select features with self.set_feature_list() first !\"\n",
    "\n",
    "        level_dict = OrderedDict()\n",
    "        for feature in self.feature_list:\n",
    "            level_dict[feature] = list(self.reference_df[feature].unique())\n",
    "\n",
    "        self.level_dict = level_dict\n",
    "\n",
    "    def measure_slices(self):\n",
    "        assert self.level_dict is not None, \"please run self.get_unique_levels() first !\"\n",
    "\n",
    "        self.slice_list = []\n",
    "\n",
    "        for feature_levels in itertools.product(*self.level_dict.values()):\n",
    "            feature_level_dict=dict(zip(list(self.level_dict.keys()), feature_levels))\n",
    "\n",
    "            # format the current feature level dict into a query and subset the reference df with it\n",
    "            data_query = ' and '.join([\"{} == '{}'\".format(k,v) for k,v in feature_level_dict.items()])\n",
    "            # then get its length and save it as the reference n in the current DataSlice \n",
    "            reference_n = len(self.reference_df.query(data_query))\n",
    "\n",
    "            self.slice_list.append(DataSlice(\n",
    "                feature_dict=feature_level_dict,\n",
    "                reference_n=reference_n\n",
    "            ))\n",
    "\n",
    "        \n",
    "    def coerce_to_strings(self):\n",
    "        assert self.target_df is not None\n",
    "        assert self.reference_df is not None\n",
    "        assert self.feature_list is not None\n",
    "        \n",
    "        for df in [self.target_df, self.reference_df]:\n",
    "            for feature in self.feature_list:\n",
    "                df[feature] = df[feature].astype(str)\n",
    "\n",
    "    def sample_slices(self):\n",
    "        assert self.slice_list is not None, \"please run self.measure_slices() first !\"\n",
    "        assert self.target_df is not None, \"please select a target dataframe with self.set_target() first !\"\n",
    "        \n",
    "        # coerce all feature cols to strings\n",
    "        self.coerce_to_strings()\n",
    "\n",
    "        for data_slice in self.slice_list:\n",
    "            # format the current feature dict into a query and subset the target df with it\n",
    "            data_query = ' and '.join([\"{} == '{}'\".format(k,v) for k,v in data_slice.feature_dict.items()]) \n",
    "            # then take a sample with \n",
    "            target_subset_df = self.target_df.query(data_query)\n",
    "            \n",
    "            # get the reference n and correct it if it's bigger than\n",
    "            ref_n = data_slice.reference_n\n",
    "            \n",
    "            if ref_n > len(target_subset_df):\n",
    "                ref_n = len(target_subset_df)\n",
    "                            \n",
    "            # if either our reference n or subset length is less than 1 skip it\n",
    "            if ref_n < 1:\n",
    "                continue\n",
    "            \n",
    "            # sample the ref_n multiplied by the target_ratio\n",
    "            data_slice.target_slice = target_subset_df.sample(\n",
    "                min(int(ref_n * self.target_ratio), len(target_subset_df)), \n",
    "                random_state=self.seed\n",
    "            )\n",
    "            data_slice.target_n = len(data_slice.target_slice)\n",
    "\n",
    "    def merge_slices(self):\n",
    "        # filter out data slices without a dataframe\n",
    "        valid_slices = [data_slice for data_slice in self.slice_list if data_slice.target_slice is not None]\n",
    "        assert len(valid_slices) > 0, f\"no valid slices found in {valid_slices} please run self.sample_slices() first !\"\n",
    "\n",
    "        # merge each of the target slices\n",
    "        balanced_target_df = pd.concat([data_slice.target_slice for data_slice in valid_slices], axis=0)\n",
    "        return balanced_target_df\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class DataSlice:\n",
    "    feature_dict: dict\n",
    "    reference_n: int\n",
    "    target_n: int = 0\n",
    "    target_slice: pd.DataFrame or None = None\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f\"DataSlice(feature_dict: {self.feature_dict}, reference_n: {self.reference_n}, target_n: {self.target_n})\"\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "f01d08b5-0c72-4792-a09c-b1a6c4a1c447",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this script operates on a per-image basis, so we'll balance based on the number of images\n",
    "# instead of the number of exams (like we did previously). since our model is an image-level classifier\n",
    "# this is fine, but if you want to stitch images together to get exam-level predictions this needs to\n",
    "# be modified\n",
    "n_pos_images = len(scr_br0_meta_filt)\n",
    "n_neg_images = len(scr_br12_meta_filt)\n",
    "n_neg_scale_factor = n_neg_images / n_pos_images\n",
    "\n",
    "# we'll sample 10_000 positive images\n",
    "n_pos_sample = 10_000\n",
    "\n",
    "# get a list of all positive image paths (we'll use the anon_dicom_path)\n",
    "total_pos_path_list = list(scr_br0_meta_filt.dropna(subset='tissueden').anon_dicom_path.unique())\n",
    "# randomly sample n_pos_sample of them, then filter the dataframe to get the subset\n",
    "# corresponding to the selected accessions\n",
    "sample_pos_path_list = random_generator.sample(total_pos_path_list, n_pos_sample)\n",
    "pos_sample = scr_br0_meta_filt[scr_br0_meta_filt.anon_dicom_path.isin(sample_pos_path_list)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "265c169c-35de-459e-807d-d492918ededc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "reference dataframe:\n",
      "Patients: 7016\n",
      "Exams: 7402\n",
      "Images: 10000\n",
      "\n",
      "\n",
      "target dataframe:\n",
      "Patients: 12564\n",
      "Exams: 32607\n",
      "Images: 156525\n",
      "\n",
      "balancing distribution based on tissueden, Race, Ethnicity, age_at_study_bins\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_4876/845463823.py:74: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[feature] = df[feature].astype(str)\n",
      "/tmp/ipykernel_4876/845463823.py:74: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[feature] = df[feature].astype(str)\n",
      "/tmp/ipykernel_4876/845463823.py:74: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[feature] = df[feature].astype(str)\n",
      "/tmp/ipykernel_4876/845463823.py:74: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[feature] = df[feature].astype(str)\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "no valid slices found in [] please run self.sample_slices() first !",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[107], line 18\u001b[0m\n\u001b[1;32m     16\u001b[0m balancer\u001b[38;5;241m.\u001b[39mmeasure_slices()\n\u001b[1;32m     17\u001b[0m balancer\u001b[38;5;241m.\u001b[39msample_slices()\n\u001b[0;32m---> 18\u001b[0m neg_sample_bal \u001b[38;5;241m=\u001b[39m balancer\u001b[38;5;241m.\u001b[39mmerge_slices()\n",
      "Cell \u001b[0;32mIn[105], line 109\u001b[0m, in \u001b[0;36mDataBalancer.merge_slices\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    106\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmerge_slices\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    107\u001b[0m     \u001b[38;5;66;03m# filter out data slices without a dataframe\u001b[39;00m\n\u001b[1;32m    108\u001b[0m     valid_slices \u001b[38;5;241m=\u001b[39m [data_slice \u001b[38;5;28;01mfor\u001b[39;00m data_slice \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mslice_list \u001b[38;5;28;01mif\u001b[39;00m data_slice\u001b[38;5;241m.\u001b[39mtarget_slice \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m]\n\u001b[0;32m--> 109\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(valid_slices) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mno valid slices found in \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mvalid_slices\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m please run self.sample_slices() first !\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    111\u001b[0m     \u001b[38;5;66;03m# merge each of the target slices\u001b[39;00m\n\u001b[1;32m    112\u001b[0m     balanced_target_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mconcat([data_slice\u001b[38;5;241m.\u001b[39mtarget_slice \u001b[38;5;28;01mfor\u001b[39;00m data_slice \u001b[38;5;129;01min\u001b[39;00m valid_slices], axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n",
      "\u001b[0;31mAssertionError\u001b[0m: no valid slices found in [] please run self.sample_slices() first !"
     ]
    }
   ],
   "source": [
    "# instantiate the balancer then set the reference dataframe\n",
    "balancer = DataBalancer()\n",
    "balancer.set_reference(pos_sample)\n",
    "\n",
    "# set the target dataframe (the one to rebalance)\n",
    "balancer.set_target(scr_br12_meta_filt)\n",
    "\n",
    "# select features\n",
    "feature_list = ['tissueden', 'Race', 'Ethnicity', 'age_at_study_bins']\n",
    "balancer.set_feature_list(feature_list)\n",
    "\n",
    "# set the dataset balance and run the balancer\n",
    "n_neg_sample = n_pos_sample * n_neg_scale_factor\n",
    "balancer.set_balance(n_neg_sample, n_pos_sample)\n",
    "balancer.get_unique_levels()\n",
    "balancer.measure_slices()\n",
    "balancer.sample_slices()\n",
    "neg_sample_bal = balancer.merge_slices()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "456a00f0-56c3-4cfc-9492-2a3609830f7b",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'neg_sample_bal' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[108], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m n_pos_images \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(pos_sample)\n\u001b[0;32m----> 2\u001b[0m n_neg_images \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(neg_sample_bal)\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpositive images: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mn_pos_images\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m(n_pos_images\u001b[38;5;250m \u001b[39m\u001b[38;5;241m/\u001b[39m(n_pos_images\u001b[38;5;250m \u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;250m \u001b[39mn_neg_images))\u001b[38;5;250m \u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;241m100\u001b[39m\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.1f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m%)\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnegative images: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mn_neg_images\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m(n_neg_images\u001b[38;5;250m \u001b[39m\u001b[38;5;241m/\u001b[39m(n_pos_images\u001b[38;5;250m \u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;250m \u001b[39mn_neg_images))\u001b[38;5;250m \u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;241m100\u001b[39m\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.1f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m%)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'neg_sample_bal' is not defined"
     ]
    }
   ],
   "source": [
    "n_pos_images = len(pos_sample)\n",
    "n_neg_images = len(neg_sample_bal)\n",
    "print(f'positive images: {n_pos_images} ({(n_pos_images /(n_pos_images + n_neg_images)) * 100:.1f}%)')\n",
    "print(f'negative images: {n_neg_images} ({(n_neg_images /(n_pos_images + n_neg_images)) * 100:.1f}%)\\n')\n",
    "\n",
    "n_pos_exams = pos_sample.acc_anon.nunique()\n",
    "n_neg_exams = neg_sample_bal.acc_anon.nunique()\n",
    "print(f'positive exams: {n_pos_exams} ({(n_pos_exams /(n_pos_exams + n_neg_exams)) * 100:.1f}%)')\n",
    "print(f'negative exams: {n_neg_exams} ({(n_neg_exams /(n_pos_exams + n_neg_exams)) * 100:.1f}%)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "ec7f0d8c-dcc9-45d9-bb09-e45c0834351d",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'neg_sample_bal' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[109], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m merged_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mconcat([pos_sample, neg_sample_bal])\n\u001b[1;32m      3\u001b[0m column_list \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLabel\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtissueden\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRace\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEthnicity\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mage_at_study_bins\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmass\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124masymmetry\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124march_distortion\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcalcification\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m      4\u001b[0m rename_dict \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtissueden\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTissue Density\u001b[39m\u001b[38;5;124m'\u001b[39m, \n\u001b[1;32m      6\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmass\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMass\u001b[39m\u001b[38;5;124m'\u001b[39m, \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mage_at_study_bins\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAge Bins\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m     11\u001b[0m }\n",
      "\u001b[0;31mNameError\u001b[0m: name 'neg_sample_bal' is not defined"
     ]
    }
   ],
   "source": [
    "merged_df = pd.concat([pos_sample, neg_sample_bal])\n",
    "\n",
    "column_list = ['Label', 'tissueden', 'Race', 'Ethnicity', 'age_at_study_bins', 'mass', 'asymmetry', 'arch_distortion', 'calcification']\n",
    "rename_dict = {\n",
    "    'tissueden': 'Tissue Density', \n",
    "    'mass': 'Mass', \n",
    "    'asymmetry': 'Asymmetry', \n",
    "    'arch_distortion': 'Architectural Distortion',\n",
    "    'calcification': 'Calcification',\n",
    "    'age_at_study_bins': 'Age Bins'\n",
    "}\n",
    "\n",
    "mytable = TableOne(\n",
    "    merged_df.reset_index(), columns=column_list, \n",
    "    categorical=['Race', 'Ethnicity', 'age_at_study_bins', 'tissueden', 'mass', 'asymmetry', 'arch_distortion', 'calcification'], \n",
    "    groupby='Label', \n",
    "    rename=rename_dict, \n",
    "    pval=False\n",
    ")\n",
    "print(mytable.tabulate(tablefmt=\"fancy_grid\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acd3d433-8f05-4fbc-aaed-03bbacd3ac7a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "69442d98-d18c-4fb6-8bd2-fbf7cfd85e8b",
   "metadata": {},
   "source": [
    "---\n",
    "# 5. Pitfalls"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e075352-1257-4195-9c52-71524171eb62",
   "metadata": {},
   "source": [
    "## 5.1. Multiple findings per exam, multiple pathologies per finding\n",
    "In Magview, each exam can have multiple findings, and each finding can have multiple pathologies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "56db1b28-3e04-4c27-8e70-40bcbe18aa1b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>empi_anon</th>\n",
       "      <th>acc_anon</th>\n",
       "      <th>study_date_anon</th>\n",
       "      <th>desc</th>\n",
       "      <th>side</th>\n",
       "      <th>asses</th>\n",
       "      <th>path_severity</th>\n",
       "      <th>bside</th>\n",
       "      <th>procdate_anon</th>\n",
       "      <th>pdate_anon</th>\n",
       "      <th>massshape</th>\n",
       "      <th>massmargin</th>\n",
       "      <th>massdens</th>\n",
       "      <th>calcdistri</th>\n",
       "      <th>calcfind</th>\n",
       "      <th>calcnumber</th>\n",
       "      <th>tissueden</th>\n",
       "      <th>ETHNICITY_DESC</th>\n",
       "      <th>ETHNIC_GROUP_DESC</th>\n",
       "      <th>MARITAL_STATUS_DESC</th>\n",
       "      <th>age_at_study</th>\n",
       "      <th>numfind</th>\n",
       "      <th>exam_laterality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>64407</th>\n",
       "      <td>16697245</td>\n",
       "      <td>9080715968654535</td>\n",
       "      <td>2017-05-09</td>\n",
       "      <td>MG Screening Bilateral</td>\n",
       "      <td>L</td>\n",
       "      <td>A</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Unknown, Unavailable or Unreported</td>\n",
       "      <td>Hispanic or Latino</td>\n",
       "      <td>Separated</td>\n",
       "      <td>67.51952469934359</td>\n",
       "      <td>3</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7921</th>\n",
       "      <td>14937052</td>\n",
       "      <td>2742446296903342</td>\n",
       "      <td>2014-04-13</td>\n",
       "      <td>MG Screening Bilateral w/CAD</td>\n",
       "      <td>L</td>\n",
       "      <td>B</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>D</td>\n",
       "      <td>G</td>\n",
       "      <td>0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Caucasian or White</td>\n",
       "      <td>Non-Hispanic or Latino</td>\n",
       "      <td>Married</td>\n",
       "      <td>53.189319424765735</td>\n",
       "      <td>3</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57048</th>\n",
       "      <td>31207881</td>\n",
       "      <td>5708086376476563</td>\n",
       "      <td>2015-03-19</td>\n",
       "      <td>MG Screen Bilat w/Tomo/CAD Stnd Protocol</td>\n",
       "      <td>L</td>\n",
       "      <td>A</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>O</td>\n",
       "      <td>D</td>\n",
       "      <td>=</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Caucasian or White</td>\n",
       "      <td>Non-Hispanic or Latino</td>\n",
       "      <td>Married</td>\n",
       "      <td>41.46560162084095</td>\n",
       "      <td>4</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15814</th>\n",
       "      <td>11788704</td>\n",
       "      <td>5410014139786648</td>\n",
       "      <td>2015-08-06</td>\n",
       "      <td>MG Screening Bilateral</td>\n",
       "      <td>L</td>\n",
       "      <td>A</td>\n",
       "      <td>0.0</td>\n",
       "      <td>L</td>\n",
       "      <td>2015-10-17</td>\n",
       "      <td>2015-10-18 00:00:00</td>\n",
       "      <td>F</td>\n",
       "      <td>S</td>\n",
       "      <td>-</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Caucasian or White</td>\n",
       "      <td>Non-Hispanic or Latino</td>\n",
       "      <td>Single</td>\n",
       "      <td>51.37134917212537</td>\n",
       "      <td>3</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66629</th>\n",
       "      <td>55604797</td>\n",
       "      <td>6465898879351049</td>\n",
       "      <td>2017-05-19</td>\n",
       "      <td>MG Screen Bilat w/Tomo/CAD Stnd Protocol</td>\n",
       "      <td>L</td>\n",
       "      <td>A</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>African American  or Black</td>\n",
       "      <td>Non-Hispanic or Latino</td>\n",
       "      <td>Single</td>\n",
       "      <td>41.64904139030918</td>\n",
       "      <td>3</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3380</th>\n",
       "      <td>82711953</td>\n",
       "      <td>7037439488424587</td>\n",
       "      <td>2013-04-11</td>\n",
       "      <td>MG Screening Bilateral w/CAD</td>\n",
       "      <td>L</td>\n",
       "      <td>A</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Caucasian or White</td>\n",
       "      <td>Non-Hispanic or Latino</td>\n",
       "      <td>Married</td>\n",
       "      <td>41.22466580422596</td>\n",
       "      <td>3</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33136</th>\n",
       "      <td>35155442</td>\n",
       "      <td>3696380592939940</td>\n",
       "      <td>2019-09-20</td>\n",
       "      <td>MG Screen Bilat w/Tomo/CAD Stnd Protocol</td>\n",
       "      <td>R</td>\n",
       "      <td>A</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Native Hawaiian or Other Pacific Islander</td>\n",
       "      <td>Hispanic or Latino</td>\n",
       "      <td>Married</td>\n",
       "      <td>50.90042916692335</td>\n",
       "      <td>3</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51529</th>\n",
       "      <td>85601129</td>\n",
       "      <td>7282995691462931</td>\n",
       "      <td>2014-08-16</td>\n",
       "      <td>MG Screen Bilat w/Tomo/CAD Stnd Protocol</td>\n",
       "      <td>L</td>\n",
       "      <td>A</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>G</td>\n",
       "      <td>G</td>\n",
       "      <td>0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>African American  or Black</td>\n",
       "      <td>Non-Hispanic or Latino</td>\n",
       "      <td>Married</td>\n",
       "      <td>49.5999233386038</td>\n",
       "      <td>3</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18374</th>\n",
       "      <td>11244518</td>\n",
       "      <td>5614746830415826</td>\n",
       "      <td>2016-04-07</td>\n",
       "      <td>MG Screen Bilat w/Tomo/CAD Stnd Protocol</td>\n",
       "      <td>L</td>\n",
       "      <td>B</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>D</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>African American  or Black</td>\n",
       "      <td>Non-Hispanic or Latino</td>\n",
       "      <td>Single</td>\n",
       "      <td>58.42693552913475</td>\n",
       "      <td>3</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102715</th>\n",
       "      <td>35842157</td>\n",
       "      <td>7053563114681046</td>\n",
       "      <td>2019-09-08</td>\n",
       "      <td>MG Screen Bilat w/Tomo/CAD Stnd Protocol</td>\n",
       "      <td>R</td>\n",
       "      <td>A</td>\n",
       "      <td>4.0</td>\n",
       "      <td>R</td>\n",
       "      <td>2019-11-02</td>\n",
       "      <td>2019-11-03 00:00:00</td>\n",
       "      <td>F</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Caucasian or White</td>\n",
       "      <td>Non-Hispanic or Latino</td>\n",
       "      <td>Single</td>\n",
       "      <td>44.41158956036058</td>\n",
       "      <td>3</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       empi_anon          acc_anon study_date_anon  \\\n",
       "64407   16697245  9080715968654535      2017-05-09   \n",
       "7921    14937052  2742446296903342      2014-04-13   \n",
       "57048   31207881  5708086376476563      2015-03-19   \n",
       "15814   11788704  5410014139786648      2015-08-06   \n",
       "66629   55604797  6465898879351049      2017-05-19   \n",
       "3380    82711953  7037439488424587      2013-04-11   \n",
       "33136   35155442  3696380592939940      2019-09-20   \n",
       "51529   85601129  7282995691462931      2014-08-16   \n",
       "18374   11244518  5614746830415826      2016-04-07   \n",
       "102715  35842157  7053563114681046      2019-09-08   \n",
       "\n",
       "                                            desc side asses  path_severity  \\\n",
       "64407                     MG Screening Bilateral    L     A            NaN   \n",
       "7921                MG Screening Bilateral w/CAD    L     B            NaN   \n",
       "57048   MG Screen Bilat w/Tomo/CAD Stnd Protocol    L     A            NaN   \n",
       "15814                     MG Screening Bilateral    L     A            0.0   \n",
       "66629   MG Screen Bilat w/Tomo/CAD Stnd Protocol    L     A            NaN   \n",
       "3380                MG Screening Bilateral w/CAD    L     A            NaN   \n",
       "33136   MG Screen Bilat w/Tomo/CAD Stnd Protocol    R     A            NaN   \n",
       "51529   MG Screen Bilat w/Tomo/CAD Stnd Protocol    L     A            NaN   \n",
       "18374   MG Screen Bilat w/Tomo/CAD Stnd Protocol    L     B            NaN   \n",
       "102715  MG Screen Bilat w/Tomo/CAD Stnd Protocol    R     A            4.0   \n",
       "\n",
       "       bside procdate_anon           pdate_anon massshape massmargin massdens  \\\n",
       "64407    NaN           NaN                  NaN       NaN        NaN      NaN   \n",
       "7921     NaN           NaN                  NaN       NaN        NaN      NaN   \n",
       "57048    NaN           NaN                  NaN         O          D        =   \n",
       "15814      L    2015-10-17  2015-10-18 00:00:00         F          S        -   \n",
       "66629    NaN           NaN                  NaN         S        NaN      NaN   \n",
       "3380     NaN           NaN                  NaN         S        NaN      NaN   \n",
       "33136    NaN           NaN                  NaN       NaN        NaN      NaN   \n",
       "51529    NaN           NaN                  NaN       NaN        NaN      NaN   \n",
       "18374    NaN           NaN                  NaN       NaN        NaN      NaN   \n",
       "102715     R    2019-11-02  2019-11-03 00:00:00         F        NaN      NaN   \n",
       "\n",
       "       calcdistri calcfind calcnumber tissueden  \\\n",
       "64407         NaN      NaN          0       2.0   \n",
       "7921            D        G          0       3.0   \n",
       "57048         NaN      NaN          0       3.0   \n",
       "15814         NaN      NaN          0       2.0   \n",
       "66629         NaN      NaN          0       3.0   \n",
       "3380          NaN      NaN          0       4.0   \n",
       "33136         NaN      NaN          0       3.0   \n",
       "51529           G        G          0       3.0   \n",
       "18374           D        9          0       3.0   \n",
       "102715        NaN      NaN          0       4.0   \n",
       "\n",
       "                                   ETHNICITY_DESC       ETHNIC_GROUP_DESC  \\\n",
       "64407          Unknown, Unavailable or Unreported      Hispanic or Latino   \n",
       "7921                           Caucasian or White  Non-Hispanic or Latino   \n",
       "57048                          Caucasian or White  Non-Hispanic or Latino   \n",
       "15814                          Caucasian or White  Non-Hispanic or Latino   \n",
       "66629                  African American  or Black  Non-Hispanic or Latino   \n",
       "3380                           Caucasian or White  Non-Hispanic or Latino   \n",
       "33136   Native Hawaiian or Other Pacific Islander      Hispanic or Latino   \n",
       "51529                  African American  or Black  Non-Hispanic or Latino   \n",
       "18374                  African American  or Black  Non-Hispanic or Latino   \n",
       "102715                         Caucasian or White  Non-Hispanic or Latino   \n",
       "\n",
       "       MARITAL_STATUS_DESC        age_at_study numfind exam_laterality  \n",
       "64407            Separated   67.51952469934359       3               B  \n",
       "7921               Married  53.189319424765735       3               B  \n",
       "57048              Married   41.46560162084095       4               B  \n",
       "15814               Single   51.37134917212537       3               B  \n",
       "66629               Single   41.64904139030918       3               B  \n",
       "3380               Married   41.22466580422596       3               B  \n",
       "33136              Married   50.90042916692335       3               B  \n",
       "51529              Married    49.5999233386038       3               B  \n",
       "18374               Single   58.42693552913475       3               B  \n",
       "102715              Single   44.41158956036058       3               B  "
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mag_screen[mag_screen.numfind.astype(int) > 2].sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "f637818d-10be-4941-b229-22e371968c7d",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'mag_full' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[111], line 5\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# HIGHLIGHT SPECIFIC COLUMNS LIKE PATH + FINDING TYPE (MASS, CALC, etc.), numfind, side, btype, bside, path1, path2, procdate\u001b[39;00m\n\u001b[1;32m      4\u001b[0m test_acc \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m2570298602359965\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m----> 5\u001b[0m mag_full\u001b[38;5;241m.\u001b[39mloc[mag_full\u001b[38;5;241m.\u001b[39macc_anon \u001b[38;5;241m==\u001b[39m test_acc, column_list]\n",
      "\u001b[0;31mNameError\u001b[0m: name 'mag_full' is not defined"
     ]
    }
   ],
   "source": [
    "column_list = ['empi_anon', 'acc_anon', 'numfind', 'side', 'asses', 'path_severity', 'mass', 'asymmetry', 'arch_distortion', 'calcification', 'path1', 'path2', 'path3', 'bside']\n",
    "# HIGHLIGHT SPECIFIC COLUMNS LIKE PATH + FINDING TYPE (MASS, CALC, etc.), numfind, side, btype, bside, path1, path2, procdate\n",
    "\n",
    "test_acc = '2570298602359965'\n",
    "mag_full.loc[mag_full.acc_anon == test_acc, column_list]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1571ab17-7e17-4ebf-a12d-0e9a5ac3b3a2",
   "metadata": {},
   "source": [
    "## 5.2. Lesion visiblity on CC or MLO views"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "ada21e84-3544-46ae-8124-06bcd680dd79",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_rois(ax, roi_list: list, match_level_list: list):\n",
    "    \"\"\"\n",
    "    function to plot the rois on the given matplotlib axes\n",
    "    \"\"\"\n",
    "    # set our dicts to color primary/secondary ROIs differently\n",
    "    color_dict = {1: 'xkcd:bright green', 2: 'xkcd:bright red'}\n",
    "    label_dict = {1: 'Primary ROI', 2: 'Secondary ROI'}\n",
    "    \n",
    "    # zip the rois and their match levels together\n",
    "    for roi, match_level in zip(roi_list, match_level_list):\n",
    "        # unpack our ROI values\n",
    "        ymin, xmin, ymax, xmax = roi\n",
    "        \n",
    "        # format the roi into a patch\n",
    "        roi_patch = pat.Rectangle(\n",
    "            (xmax, ymax),\n",
    "            xmin - xmax,\n",
    "            ymin - ymax,\n",
    "            edgecolor=color_dict[match_level], \n",
    "            fc='None', \n",
    "            label=label_dict[match_level]\n",
    "        )\n",
    "        \n",
    "        # add the patch to the axes\n",
    "        ax.add_patch(roi_patch)\n",
    "        \n",
    "def plot_image(image, roi_list: list, match_level_list: list):\n",
    "    \"\"\"\n",
    "    function to take a cv2 image and a list of rois and match levels\n",
    "    and plot them\n",
    "    \"\"\"\n",
    "    # get a figure and axis\n",
    "    fig, ax = plt.subplots(1, 1, dpi=150)\n",
    "    \n",
    "    # plot our image on the axes\n",
    "    ax.imshow(image, cmap='gray')\n",
    "    \n",
    "    # plot our rois on the axes\n",
    "    plot_rois(ax, roi_list, match_level_list)\n",
    "    \n",
    "    # get a legend\n",
    "    ax.legend()\n",
    "    \n",
    "    # show the image\n",
    "    fig.show()\n",
    "    \n",
    "def parse_roi(roi_coords: str):\n",
    "    \"\"\"\n",
    "    function to convert our ROI_coords string into a nested list.\n",
    "    since we don't care about mapping back to the original ROI_SSC image \n",
    "    we can discard one level of nesting to make it easier to use\n",
    "    \"\"\"\n",
    "    # remove \"][)(,\" symbols from the string\n",
    "    roi_coords = roi_coords.translate({ord(c): None for c in \"][)(,\"})\n",
    "    \n",
    "    # split the list on whitespace, map each value to an \n",
    "    # integer, and send it to a list\n",
    "    # we now have a list like this \n",
    "    # [ymin0, xmin0, ymax0, xmax0, ymin1, ...]\n",
    "    flat_roi_list = list(map(int, roi_coords.split()))\n",
    "    \n",
    "    # we need to reformat it to \n",
    "    # [[ymin0, xmin0, ymax0, xmax0], [ymin1, ...]]\n",
    "    # get an empty list\n",
    "    out_roi_list = []\n",
    "    \n",
    "    # iterate over the number of rois (number of coords mod 4)\n",
    "    for i in range(len(flat_roi_list) // 4):\n",
    "        # for each, append the relevant 4 flat_roi_list \n",
    "        # indices to the out_roi_list\n",
    "        out_roi_list.append(flat_roi_list[4*i:4*i+4])\n",
    "        \n",
    "    return out_roi_list\n",
    "\n",
    "def parse_match_level(match_level: str):\n",
    "    \"\"\"\n",
    "    function to convert our ROI_match_level string into a nested list.\n",
    "    since we don't care about mapping back to the original ROI_SSC image \n",
    "    we can discard one level of nesting to make it easier to use\n",
    "    \"\"\"\n",
    "    # remove \"][' \" symbols from the string\n",
    "    match_level = match_level.translate({ord(c): None for c in \"][',\"})\n",
    "    \n",
    "    # split the list on commas, map each value to an integer\n",
    "    # and sent it to a list\n",
    "    match_level_list = list(map(int, match_level.split()))\n",
    "    \n",
    "    return match_level_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "27f04b82-5a89-4865-9e4b-151786358016",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8281840728143811\n"
     ]
    }
   ],
   "source": [
    "# test_acc = scr_br0_meta[scr_br0_meta.num_roi > 0].sample(1).acc_anon.item()\n",
    "test_acc = 8281840728143811\n",
    "print(test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "6b586018-afa0-4213-8063-98acbbac7035",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as pat\n",
    "import cv2 as cv\n",
    "\n",
    "# correct path for server\n",
    "scr_br0_meta.png_path = scr_br0_meta.png_path.str.replace('/ssd-data', '/mnt/NAS3')\n",
    "\n",
    "for i, row in scr_br0_meta[scr_br0_meta.acc_anon == test_acc].iterrows():\n",
    "    img = cv.imread(row.png_path)\n",
    "    roi_list = parse_roi(row.PNG_ROI_coords)\n",
    "    match_level_list = parse_match_level(row.ROI_match_level)\n",
    "    plot_image(img, roi_list, match_level_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7aa392bf-b0b8-4939-af1d-b998b5c99e5e",
   "metadata": {},
   "source": [
    "## 5.4. Multiple CC and MLO views - which to take?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "dff1df01-c8cb-4592-995a-33cb5c8a6d6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_4876/1374548159.py:1: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  grouped_df = meta_df.groupby('acc_anon').apply(lambda x: (x['ViewPosition'] == 'CC').sum())\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "acc_anon\n",
       "1000032271483397    2\n",
       "1000242041095481    2\n",
       "1000443661283482    5\n",
       "1000449157413064    2\n",
       "1000456712334630    3\n",
       "                   ..\n",
       "9999613531810027    2\n",
       "9999684010956713    1\n",
       "9999756786212166    4\n",
       "9999812314732894    2\n",
       "9999902806302319    3\n",
       "Length: 86221, dtype: int64"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grouped_df = meta_df.groupby('acc_anon').apply(lambda x: (x['ViewPosition'] == 'CC').sum())\n",
    "grouped_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "723c3b2e-7907-40a4-b328-0c6f2551678a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ WARN:0@9.374] global loadsave.cpp:241 findDecoder imread_('/data/mammo/png/cohort_2/extracted-images/361cfed1c7d6980c5d1029decf05a9aa422f8d878caf8d3f62c36592/1801c7063c43e0ddda117c8766c840537ea887aea7e5464ac8c93cf9/1a5061a138fa77f51dd598ab50621fbf778f02616453dc4bf5c6b039.png'): can't open/read file: check file path/integrity\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "Image data of dtype object cannot be converted to float",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[116], line 20\u001b[0m\n\u001b[1;32m     18\u001b[0m     ax\u001b[38;5;241m.\u001b[39mset_title(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlaterality\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m-\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mview_position\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     19\u001b[0m     img \u001b[38;5;241m=\u001b[39m cv\u001b[38;5;241m.\u001b[39mimread(row\u001b[38;5;241m.\u001b[39mpng_path)\n\u001b[0;32m---> 20\u001b[0m     ax\u001b[38;5;241m.\u001b[39mimshow(img)\n\u001b[1;32m     22\u001b[0m fig\u001b[38;5;241m.\u001b[39mshow()\n",
      "File \u001b[0;32m/opt/tljh/user/envs/pandas/lib/python3.11/site-packages/matplotlib/__init__.py:1473\u001b[0m, in \u001b[0;36m_preprocess_data.<locals>.inner\u001b[0;34m(ax, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1470\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m   1471\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minner\u001b[39m(ax, \u001b[38;5;241m*\u001b[39margs, data\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m   1472\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1473\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m func(\n\u001b[1;32m   1474\u001b[0m             ax,\n\u001b[1;32m   1475\u001b[0m             \u001b[38;5;241m*\u001b[39m\u001b[38;5;28mmap\u001b[39m(sanitize_sequence, args),\n\u001b[1;32m   1476\u001b[0m             \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m{k: sanitize_sequence(v) \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m kwargs\u001b[38;5;241m.\u001b[39mitems()})\n\u001b[1;32m   1478\u001b[0m     bound \u001b[38;5;241m=\u001b[39m new_sig\u001b[38;5;241m.\u001b[39mbind(ax, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1479\u001b[0m     auto_label \u001b[38;5;241m=\u001b[39m (bound\u001b[38;5;241m.\u001b[39marguments\u001b[38;5;241m.\u001b[39mget(label_namer)\n\u001b[1;32m   1480\u001b[0m                   \u001b[38;5;129;01mor\u001b[39;00m bound\u001b[38;5;241m.\u001b[39mkwargs\u001b[38;5;241m.\u001b[39mget(label_namer))\n",
      "File \u001b[0;32m/opt/tljh/user/envs/pandas/lib/python3.11/site-packages/matplotlib/axes/_axes.py:5895\u001b[0m, in \u001b[0;36mAxes.imshow\u001b[0;34m(self, X, cmap, norm, aspect, interpolation, alpha, vmin, vmax, origin, extent, interpolation_stage, filternorm, filterrad, resample, url, **kwargs)\u001b[0m\n\u001b[1;32m   5892\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m aspect \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   5893\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mset_aspect(aspect)\n\u001b[0;32m-> 5895\u001b[0m im\u001b[38;5;241m.\u001b[39mset_data(X)\n\u001b[1;32m   5896\u001b[0m im\u001b[38;5;241m.\u001b[39mset_alpha(alpha)\n\u001b[1;32m   5897\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m im\u001b[38;5;241m.\u001b[39mget_clip_path() \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   5898\u001b[0m     \u001b[38;5;66;03m# image does not already have clipping set, clip to Axes patch\u001b[39;00m\n",
      "File \u001b[0;32m/opt/tljh/user/envs/pandas/lib/python3.11/site-packages/matplotlib/image.py:729\u001b[0m, in \u001b[0;36m_ImageBase.set_data\u001b[0;34m(self, A)\u001b[0m\n\u001b[1;32m    727\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(A, PIL\u001b[38;5;241m.\u001b[39mImage\u001b[38;5;241m.\u001b[39mImage):\n\u001b[1;32m    728\u001b[0m     A \u001b[38;5;241m=\u001b[39m pil_to_array(A)  \u001b[38;5;66;03m# Needed e.g. to apply png palette.\u001b[39;00m\n\u001b[0;32m--> 729\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_A \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_normalize_image_array(A)\n\u001b[1;32m    730\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_imcache \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    731\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstale \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m/opt/tljh/user/envs/pandas/lib/python3.11/site-packages/matplotlib/image.py:692\u001b[0m, in \u001b[0;36m_ImageBase._normalize_image_array\u001b[0;34m(A)\u001b[0m\n\u001b[1;32m    690\u001b[0m A \u001b[38;5;241m=\u001b[39m cbook\u001b[38;5;241m.\u001b[39msafe_masked_invalid(A, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m    691\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m A\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m!=\u001b[39m np\u001b[38;5;241m.\u001b[39muint8 \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m np\u001b[38;5;241m.\u001b[39mcan_cast(A\u001b[38;5;241m.\u001b[39mdtype, \u001b[38;5;28mfloat\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msame_kind\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m--> 692\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mImage data of dtype \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mA\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m cannot be \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    693\u001b[0m                     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mconverted to float\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    694\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m A\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m3\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m A\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m    695\u001b[0m     A \u001b[38;5;241m=\u001b[39m A\u001b[38;5;241m.\u001b[39msqueeze(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)  \u001b[38;5;66;03m# If just (M, N, 1), assume scalar and apply colormap.\u001b[39;00m\n",
      "\u001b[0;31mTypeError\u001b[0m: Image data of dtype object cannot be converted to float"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 832x624 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import cv2 as cv\n",
    "\n",
    "multi_view_df = meta_df[meta_df.acc_anon == '1000032271483397']\n",
    "\n",
    "for laterality in ['L', 'R']:\n",
    "    for view_position in ['CC', 'MLO']:\n",
    "        df_subset = multi_view_df[(multi_view_df.ImageLateralityFinal == laterality) & (multi_view_df.ViewPosition == view_position)]\n",
    "        n_images = len(df_subset)\n",
    "\n",
    "        fig, axs = plt.subplots(1, n_images, dpi=130)\n",
    "        for ax_idx, (i, row) in zip(range(n_images), df_subset.iterrows()):\n",
    "            try:\n",
    "                ax = axs[ax_idx]\n",
    "            except TypeError:\n",
    "                ax = axs\n",
    "                \n",
    "            ax.set_title(f'{laterality}-{view_position}')\n",
    "            img = cv.imread(row.png_path)\n",
    "            ax.imshow(img)\n",
    "\n",
    "        fig.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a4aedc9-eb0f-4f32-be34-e598087a0e71",
   "metadata": {},
   "source": [
    "> ## Question\n",
    ">\n",
    "> **How should we handle these cases?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0884c345-d361-4aa1-8040-858933a4cbb6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3061fcc6-b044-4e3d-b857-86180a422a60",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pandas",
   "language": "python",
   "name": "pandas"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
